{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7cADFlASIn2",
        "colab_type": "code",
        "outputId": "dd55ff84-cdaf-4fff-a72d-f1560dfb8c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyoO-iE3BI6s",
        "colab_type": "code",
        "outputId": "5fc769ec-944b-4352-98fa-1420d0a64937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "path = keras.utils.get_file(\"machine.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data\")\n",
        "path"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data\n",
            "16384/8726 [========================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/machine.data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXW6OlIfBWYV",
        "colab_type": "code",
        "outputId": "70d7057d-0b1c-46f9-c239-acf23d42e71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "column_names =['vendor','Model_Name','MYCT','MMIN','MMAX','CACH','CHMIN','CHMAX','PRP','ERP']\n",
        "dataset = pd.read_csv(path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\",\", skipinitialspace=True)\n",
        "\n",
        "dataset.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vendor</th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>MYCT</th>\n",
              "      <th>MMIN</th>\n",
              "      <th>MMAX</th>\n",
              "      <th>CACH</th>\n",
              "      <th>CHMIN</th>\n",
              "      <th>CHMAX</th>\n",
              "      <th>PRP</th>\n",
              "      <th>ERP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adviser</td>\n",
              "      <td>32/60</td>\n",
              "      <td>125</td>\n",
              "      <td>256</td>\n",
              "      <td>6000</td>\n",
              "      <td>256</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>269</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7a</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>220</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7b</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>32000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>172</td>\n",
              "      <td>253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amdahl</td>\n",
              "      <td>470v/7c</td>\n",
              "      <td>29</td>\n",
              "      <td>8000</td>\n",
              "      <td>16000</td>\n",
              "      <td>32</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>132</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    vendor Model_Name  MYCT  MMIN   MMAX  CACH  CHMIN  CHMAX  PRP  ERP\n",
              "0  adviser      32/60   125   256   6000   256     16    128  198  199\n",
              "1   amdahl     470v/7    29  8000  32000    32      8     32  269  253\n",
              "2   amdahl    470v/7a    29  8000  32000    32      8     32  220  253\n",
              "3   amdahl    470v/7b    29  8000  32000    32      8     32  172  253\n",
              "4   amdahl    470v/7c    29  8000  16000    32      8     16  132  132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcyMrwtWDD5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=dataset.drop(columns=['vendor','Model_Name'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2W-2v06J1dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=dataset.pop(\"ERP\")\n",
        "X=dataset.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIAxjRw8yMFR",
        "colab_type": "code",
        "outputId": "3bfeb565-38f9-4b32-d1d7-b3983872cde1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "X_stats = X.describe()\n",
        "X_stats= X_stats.transpose()\n",
        "X_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MYCT</th>\n",
              "      <td>209.0</td>\n",
              "      <td>203.822967</td>\n",
              "      <td>260.262926</td>\n",
              "      <td>17.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MMIN</th>\n",
              "      <td>209.0</td>\n",
              "      <td>2867.980861</td>\n",
              "      <td>3878.742758</td>\n",
              "      <td>64.0</td>\n",
              "      <td>768.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>32000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MMAX</th>\n",
              "      <td>209.0</td>\n",
              "      <td>11796.153110</td>\n",
              "      <td>11726.564377</td>\n",
              "      <td>64.0</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>8000.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>64000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CACH</th>\n",
              "      <td>209.0</td>\n",
              "      <td>25.205742</td>\n",
              "      <td>40.628722</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHMIN</th>\n",
              "      <td>209.0</td>\n",
              "      <td>4.698565</td>\n",
              "      <td>6.816274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>52.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHMAX</th>\n",
              "      <td>209.0</td>\n",
              "      <td>18.267943</td>\n",
              "      <td>25.997318</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>176.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRP</th>\n",
              "      <td>209.0</td>\n",
              "      <td>105.622010</td>\n",
              "      <td>160.830733</td>\n",
              "      <td>6.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>1150.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       count          mean           std  ...     50%      75%      max\n",
              "MYCT   209.0    203.822967    260.262926  ...   110.0    225.0   1500.0\n",
              "MMIN   209.0   2867.980861   3878.742758  ...  2000.0   4000.0  32000.0\n",
              "MMAX   209.0  11796.153110  11726.564377  ...  8000.0  16000.0  64000.0\n",
              "CACH   209.0     25.205742     40.628722  ...     8.0     32.0    256.0\n",
              "CHMIN  209.0      4.698565      6.816274  ...     2.0      6.0     52.0\n",
              "CHMAX  209.0     18.267943     25.997318  ...     8.0     24.0    176.0\n",
              "PRP    209.0    105.622010    160.830733  ...    50.0    113.0   1150.0\n",
              "\n",
              "[7 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zSiKYl0FhZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_normalized = (X - X_stats['mean']) / X_stats['std']\n",
        "X_normalized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0fzKP2by-ru",
        "colab_type": "code",
        "outputId": "01437c53-24aa-4e33-ce70-d99f233079de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MYCT</th>\n",
              "      <th>MMIN</th>\n",
              "      <th>MMAX</th>\n",
              "      <th>CACH</th>\n",
              "      <th>CHMIN</th>\n",
              "      <th>CHMAX</th>\n",
              "      <th>PRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.302859</td>\n",
              "      <td>-0.673409</td>\n",
              "      <td>-0.494275</td>\n",
              "      <td>5.680569</td>\n",
              "      <td>1.658008</td>\n",
              "      <td>4.220899</td>\n",
              "      <td>0.574380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.671717</td>\n",
              "      <td>1.323114</td>\n",
              "      <td>1.722913</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>0.484346</td>\n",
              "      <td>0.528211</td>\n",
              "      <td>1.015838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.671717</td>\n",
              "      <td>1.323114</td>\n",
              "      <td>1.722913</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>0.484346</td>\n",
              "      <td>0.528211</td>\n",
              "      <td>0.711170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.671717</td>\n",
              "      <td>1.323114</td>\n",
              "      <td>1.722913</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>0.484346</td>\n",
              "      <td>0.528211</td>\n",
              "      <td>0.412720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.671717</td>\n",
              "      <td>1.323114</td>\n",
              "      <td>0.358489</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>0.484346</td>\n",
              "      <td>-0.087238</td>\n",
              "      <td>0.164011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>-0.306701</td>\n",
              "      <td>-0.481594</td>\n",
              "      <td>-0.323723</td>\n",
              "      <td>-0.620392</td>\n",
              "      <td>-0.542608</td>\n",
              "      <td>-0.394962</td>\n",
              "      <td>-0.395584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>-0.406600</td>\n",
              "      <td>-0.481594</td>\n",
              "      <td>-0.323723</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>-0.395900</td>\n",
              "      <td>-0.394962</td>\n",
              "      <td>-0.370713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>-0.302859</td>\n",
              "      <td>-0.223779</td>\n",
              "      <td>-0.323723</td>\n",
              "      <td>-0.620392</td>\n",
              "      <td>-0.395900</td>\n",
              "      <td>-0.164169</td>\n",
              "      <td>-0.333406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>1.061146</td>\n",
              "      <td>-0.607408</td>\n",
              "      <td>-0.323723</td>\n",
              "      <td>0.167228</td>\n",
              "      <td>-0.689316</td>\n",
              "      <td>-0.702686</td>\n",
              "      <td>-0.240141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>1.061146</td>\n",
              "      <td>-0.481594</td>\n",
              "      <td>-0.664828</td>\n",
              "      <td>-0.620392</td>\n",
              "      <td>-0.689316</td>\n",
              "      <td>-0.702686</td>\n",
              "      <td>-0.376931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>209 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         MYCT      MMIN      MMAX      CACH     CHMIN     CHMAX       PRP\n",
              "0   -0.302859 -0.673409 -0.494275  5.680569  1.658008  4.220899  0.574380\n",
              "1   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  1.015838\n",
              "2   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  0.711170\n",
              "3   -0.671717  1.323114  1.722913  0.167228  0.484346  0.528211  0.412720\n",
              "4   -0.671717  1.323114  0.358489  0.167228  0.484346 -0.087238  0.164011\n",
              "..        ...       ...       ...       ...       ...       ...       ...\n",
              "204 -0.306701 -0.481594 -0.323723 -0.620392 -0.542608 -0.394962 -0.395584\n",
              "205 -0.406600 -0.481594 -0.323723  0.167228 -0.395900 -0.394962 -0.370713\n",
              "206 -0.302859 -0.223779 -0.323723 -0.620392 -0.395900 -0.164169 -0.333406\n",
              "207  1.061146 -0.607408 -0.323723  0.167228 -0.689316 -0.702686 -0.240141\n",
              "208  1.061146 -0.481594 -0.664828 -0.620392 -0.689316 -0.702686 -0.376931\n",
              "\n",
              "[209 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFqgkeE0nt5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu', input_shape=[len(X_normalized.keys())]),\n",
        "    tf.keras.layers.Dense(100, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZC2j4PaoWTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4kaUyhCpQp9",
        "colab_type": "code",
        "outputId": "cab3336e-914a-438f-e73b-fb9476760040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_normalized,y,epochs=1000,validation_split=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24538.9609 - mse: 24538.9609 - val_loss: 115272.5156 - val_mse: 115272.5156\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 24404.0371 - mse: 24404.0371 - val_loss: 114643.9531 - val_mse: 114643.9531\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 24266.9102 - mse: 24266.9102 - val_loss: 113978.3125 - val_mse: 113978.3125\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 24098.0488 - mse: 24098.0488 - val_loss: 113162.2891 - val_mse: 113162.2891\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 23894.5723 - mse: 23894.5723 - val_loss: 112160.3438 - val_mse: 112160.3438\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 23645.9141 - mse: 23645.9141 - val_loss: 110871.0156 - val_mse: 110871.0156\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 23298.8770 - mse: 23298.8770 - val_loss: 109313.4062 - val_mse: 109313.4062\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22952.3945 - mse: 22952.3945 - val_loss: 107317.9609 - val_mse: 107317.9609\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 22402.4785 - mse: 22402.4785 - val_loss: 105080.6328 - val_mse: 105080.6328\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 21876.1641 - mse: 21876.1641 - val_loss: 102220.2344 - val_mse: 102220.2344\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 21195.1113 - mse: 21195.1113 - val_loss: 98754.5859 - val_mse: 98754.5859\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 20505.9766 - mse: 20505.9766 - val_loss: 94381.8047 - val_mse: 94381.8047\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 19357.7559 - mse: 19357.7559 - val_loss: 89766.8906 - val_mse: 89766.8906\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 18253.8262 - mse: 18253.8262 - val_loss: 84306.0391 - val_mse: 84306.0391\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 17253.3223 - mse: 17253.3223 - val_loss: 77795.1562 - val_mse: 77795.1562\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 15644.1553 - mse: 15644.1553 - val_loss: 71228.0000 - val_mse: 71228.0000\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 14134.1396 - mse: 14134.1396 - val_loss: 64312.7500 - val_mse: 64312.7500\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 12618.9775 - mse: 12618.9775 - val_loss: 56800.6836 - val_mse: 56800.6836\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10923.6650 - mse: 10923.6650 - val_loss: 49313.1758 - val_mse: 49313.1758\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9557.5596 - mse: 9557.5596 - val_loss: 41575.4805 - val_mse: 41575.4805\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7719.1577 - mse: 7719.1577 - val_loss: 34893.6992 - val_mse: 34893.6992\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6340.3257 - mse: 6340.3257 - val_loss: 28523.5059 - val_mse: 28523.5059\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4869.5127 - mse: 4869.5122 - val_loss: 23271.3672 - val_mse: 23271.3672\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4098.2036 - mse: 4098.2036 - val_loss: 18145.4609 - val_mse: 18145.4609\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2882.8596 - mse: 2882.8596 - val_loss: 14871.0117 - val_mse: 14871.0117\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2296.5203 - mse: 2296.5203 - val_loss: 12282.6221 - val_mse: 12282.6221\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1930.6899 - mse: 1930.6899 - val_loss: 10380.3906 - val_mse: 10380.3906\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1629.1581 - mse: 1629.1581 - val_loss: 9272.7725 - val_mse: 9272.7725\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1419.8838 - mse: 1419.8838 - val_loss: 8722.3711 - val_mse: 8722.3711\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1256.3827 - mse: 1256.3827 - val_loss: 8513.2236 - val_mse: 8513.2236\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1204.2594 - mse: 1204.2594 - val_loss: 8370.6299 - val_mse: 8370.6299\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1157.0468 - mse: 1157.0468 - val_loss: 8261.3809 - val_mse: 8261.3809\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1118.6683 - mse: 1118.6683 - val_loss: 8231.7695 - val_mse: 8231.7695\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1063.6587 - mse: 1063.6587 - val_loss: 8153.4678 - val_mse: 8153.4678\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1045.6840 - mse: 1045.6840 - val_loss: 8041.8682 - val_mse: 8041.8682\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1010.1956 - mse: 1010.1956 - val_loss: 7985.0796 - val_mse: 7985.0796\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 968.6072 - mse: 968.6072 - val_loss: 7931.4302 - val_mse: 7931.4302\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 950.1581 - mse: 950.1581 - val_loss: 7899.2056 - val_mse: 7899.2056\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 917.0223 - mse: 917.0223 - val_loss: 7845.9077 - val_mse: 7845.9077\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 895.5529 - mse: 895.5529 - val_loss: 7827.4229 - val_mse: 7827.4229\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 871.8989 - mse: 871.8989 - val_loss: 7766.6108 - val_mse: 7766.6108\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 852.1592 - mse: 852.1592 - val_loss: 7703.9180 - val_mse: 7703.9180\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 835.5198 - mse: 835.5198 - val_loss: 7691.9927 - val_mse: 7691.9927\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 822.8436 - mse: 822.8436 - val_loss: 7575.7969 - val_mse: 7575.7969\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 795.8632 - mse: 795.8632 - val_loss: 7537.5415 - val_mse: 7537.5415\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 782.4880 - mse: 782.4880 - val_loss: 7497.0952 - val_mse: 7497.0952\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 772.1149 - mse: 772.1149 - val_loss: 7510.1079 - val_mse: 7510.1079\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 750.3586 - mse: 750.3586 - val_loss: 7407.5566 - val_mse: 7407.5566\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 737.7518 - mse: 737.7518 - val_loss: 7332.1680 - val_mse: 7332.1680\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 725.1463 - mse: 725.1463 - val_loss: 7287.7490 - val_mse: 7287.7490\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 710.0871 - mse: 710.0871 - val_loss: 7216.5156 - val_mse: 7216.5156\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 699.4005 - mse: 699.4005 - val_loss: 7139.8281 - val_mse: 7139.8281\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 684.8564 - mse: 684.8564 - val_loss: 7099.1040 - val_mse: 7099.1040\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 679.8578 - mse: 679.8578 - val_loss: 7039.9502 - val_mse: 7039.9502\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 671.5630 - mse: 671.5630 - val_loss: 7045.1353 - val_mse: 7045.1353\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 663.3916 - mse: 663.3916 - val_loss: 6930.7085 - val_mse: 6930.7085\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 646.5607 - mse: 646.5607 - val_loss: 6915.0073 - val_mse: 6915.0073\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 640.4534 - mse: 640.4534 - val_loss: 6894.9976 - val_mse: 6894.9976\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 638.3578 - mse: 638.3578 - val_loss: 6767.7769 - val_mse: 6767.7769\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 623.3152 - mse: 623.3152 - val_loss: 6702.9673 - val_mse: 6702.9673\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 618.4741 - mse: 618.4741 - val_loss: 6733.8882 - val_mse: 6733.8882\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 608.2296 - mse: 608.2296 - val_loss: 6664.0386 - val_mse: 6664.0386\n",
            "Epoch 63/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 599.3451 - mse: 599.3451 - val_loss: 6645.9146 - val_mse: 6645.9146\n",
            "Epoch 64/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 596.7714 - mse: 596.7714 - val_loss: 6547.2485 - val_mse: 6547.2485\n",
            "Epoch 65/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 586.2338 - mse: 586.2338 - val_loss: 6542.1777 - val_mse: 6542.1777\n",
            "Epoch 66/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 579.4016 - mse: 579.4016 - val_loss: 6539.1025 - val_mse: 6539.1025\n",
            "Epoch 67/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 574.2175 - mse: 574.2175 - val_loss: 6449.5366 - val_mse: 6449.5366\n",
            "Epoch 68/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 572.9438 - mse: 572.9438 - val_loss: 6352.6104 - val_mse: 6352.6104\n",
            "Epoch 69/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 563.4764 - mse: 563.4764 - val_loss: 6382.0571 - val_mse: 6382.0571\n",
            "Epoch 70/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 561.6145 - mse: 561.6145 - val_loss: 6292.7114 - val_mse: 6292.7114\n",
            "Epoch 71/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 554.6036 - mse: 554.6036 - val_loss: 6355.0039 - val_mse: 6355.0039\n",
            "Epoch 72/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 550.5139 - mse: 550.5139 - val_loss: 6277.8267 - val_mse: 6277.8267\n",
            "Epoch 73/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 540.6688 - mse: 540.6688 - val_loss: 6246.8438 - val_mse: 6246.8438\n",
            "Epoch 74/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 534.1353 - mse: 534.1353 - val_loss: 6223.8657 - val_mse: 6223.8657\n",
            "Epoch 75/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 539.5597 - mse: 539.5597 - val_loss: 6297.4897 - val_mse: 6297.4897\n",
            "Epoch 76/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 526.9954 - mse: 526.9954 - val_loss: 6181.1899 - val_mse: 6181.1899\n",
            "Epoch 77/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 523.6055 - mse: 523.6055 - val_loss: 6095.3525 - val_mse: 6095.3525\n",
            "Epoch 78/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 518.8746 - mse: 518.8746 - val_loss: 6114.2134 - val_mse: 6114.2134\n",
            "Epoch 79/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 513.6179 - mse: 513.6179 - val_loss: 6099.5166 - val_mse: 6099.5166\n",
            "Epoch 80/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 506.8887 - mse: 506.8887 - val_loss: 5987.3413 - val_mse: 5987.3413\n",
            "Epoch 81/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 511.5230 - mse: 511.5230 - val_loss: 5882.4312 - val_mse: 5882.4312\n",
            "Epoch 82/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 503.0498 - mse: 503.0498 - val_loss: 5835.4487 - val_mse: 5835.4487\n",
            "Epoch 83/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 499.5981 - mse: 499.5981 - val_loss: 5907.8643 - val_mse: 5907.8643\n",
            "Epoch 84/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 493.8343 - mse: 493.8343 - val_loss: 5897.9697 - val_mse: 5897.9697\n",
            "Epoch 85/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 488.1558 - mse: 488.1558 - val_loss: 5878.6377 - val_mse: 5878.6377\n",
            "Epoch 86/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 486.1859 - mse: 486.1859 - val_loss: 5826.3672 - val_mse: 5826.3672\n",
            "Epoch 87/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 481.2750 - mse: 481.2750 - val_loss: 5839.6421 - val_mse: 5839.6421\n",
            "Epoch 88/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 476.1050 - mse: 476.1050 - val_loss: 5819.1182 - val_mse: 5819.1182\n",
            "Epoch 89/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 478.1505 - mse: 478.1505 - val_loss: 5889.3555 - val_mse: 5889.3555\n",
            "Epoch 90/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 474.5542 - mse: 474.5542 - val_loss: 5776.0332 - val_mse: 5776.0332\n",
            "Epoch 91/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 465.9484 - mse: 465.9484 - val_loss: 5757.5850 - val_mse: 5757.5850\n",
            "Epoch 92/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 465.4858 - mse: 465.4858 - val_loss: 5685.0708 - val_mse: 5685.0708\n",
            "Epoch 93/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 459.6797 - mse: 459.6797 - val_loss: 5687.8892 - val_mse: 5687.8892\n",
            "Epoch 94/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 457.0239 - mse: 457.0239 - val_loss: 5661.5635 - val_mse: 5661.5635\n",
            "Epoch 95/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 454.7472 - mse: 454.7472 - val_loss: 5612.4521 - val_mse: 5612.4521\n",
            "Epoch 96/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 450.0665 - mse: 450.0665 - val_loss: 5588.9946 - val_mse: 5588.9946\n",
            "Epoch 97/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 447.3748 - mse: 447.3748 - val_loss: 5588.2163 - val_mse: 5588.2163\n",
            "Epoch 98/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 441.8199 - mse: 441.8199 - val_loss: 5607.8564 - val_mse: 5607.8564\n",
            "Epoch 99/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 442.1185 - mse: 442.1185 - val_loss: 5674.9106 - val_mse: 5674.9106\n",
            "Epoch 100/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 447.1154 - mse: 447.1155 - val_loss: 5747.9355 - val_mse: 5747.9355\n",
            "Epoch 101/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 442.1759 - mse: 442.1759 - val_loss: 5595.7017 - val_mse: 5595.7017\n",
            "Epoch 102/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 431.0207 - mse: 431.0207 - val_loss: 5588.2153 - val_mse: 5588.2153\n",
            "Epoch 103/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 435.2327 - mse: 435.2327 - val_loss: 5449.6689 - val_mse: 5449.6689\n",
            "Epoch 104/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 424.4095 - mse: 424.4095 - val_loss: 5433.7725 - val_mse: 5433.7725\n",
            "Epoch 105/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 423.6675 - mse: 423.6675 - val_loss: 5459.6182 - val_mse: 5459.6182\n",
            "Epoch 106/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 426.8584 - mse: 426.8584 - val_loss: 5499.0288 - val_mse: 5499.0288\n",
            "Epoch 107/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 421.0862 - mse: 421.0862 - val_loss: 5517.7432 - val_mse: 5517.7432\n",
            "Epoch 108/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 421.8237 - mse: 421.8237 - val_loss: 5374.6714 - val_mse: 5374.6714\n",
            "Epoch 109/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 411.9531 - mse: 411.9531 - val_loss: 5364.9756 - val_mse: 5364.9756\n",
            "Epoch 110/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 410.2834 - mse: 410.2834 - val_loss: 5319.9282 - val_mse: 5319.9282\n",
            "Epoch 111/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 412.2215 - mse: 412.2215 - val_loss: 5272.4468 - val_mse: 5272.4468\n",
            "Epoch 112/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 406.0096 - mse: 406.0096 - val_loss: 5271.5244 - val_mse: 5271.5244\n",
            "Epoch 113/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 406.3295 - mse: 406.3295 - val_loss: 5364.9717 - val_mse: 5364.9717\n",
            "Epoch 114/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 405.7407 - mse: 405.7407 - val_loss: 5428.5352 - val_mse: 5428.5352\n",
            "Epoch 115/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 395.3937 - mse: 395.3937 - val_loss: 5336.6523 - val_mse: 5336.6523\n",
            "Epoch 116/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 392.4667 - mse: 392.4667 - val_loss: 5294.7109 - val_mse: 5294.7109\n",
            "Epoch 117/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 389.0907 - mse: 389.0907 - val_loss: 5256.7207 - val_mse: 5256.7207\n",
            "Epoch 118/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 393.4858 - mse: 393.4858 - val_loss: 5169.7075 - val_mse: 5169.7075\n",
            "Epoch 119/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 385.7467 - mse: 385.7467 - val_loss: 5202.6870 - val_mse: 5202.6870\n",
            "Epoch 120/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 383.9550 - mse: 383.9550 - val_loss: 5224.7202 - val_mse: 5224.7202\n",
            "Epoch 121/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 380.2783 - mse: 380.2783 - val_loss: 5215.8994 - val_mse: 5215.8994\n",
            "Epoch 122/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 386.6065 - mse: 386.6065 - val_loss: 5140.1255 - val_mse: 5140.1255\n",
            "Epoch 123/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 377.7871 - mse: 377.7871 - val_loss: 5189.4507 - val_mse: 5189.4507\n",
            "Epoch 124/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 373.8095 - mse: 373.8095 - val_loss: 5196.8301 - val_mse: 5196.8301\n",
            "Epoch 125/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 370.1220 - mse: 370.1220 - val_loss: 5182.2861 - val_mse: 5182.2861\n",
            "Epoch 126/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 369.2817 - mse: 369.2817 - val_loss: 5136.4438 - val_mse: 5136.4438\n",
            "Epoch 127/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 365.6058 - mse: 365.6058 - val_loss: 5126.1616 - val_mse: 5126.1616\n",
            "Epoch 128/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 363.4421 - mse: 363.4421 - val_loss: 5123.9380 - val_mse: 5123.9380\n",
            "Epoch 129/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 362.7295 - mse: 362.7295 - val_loss: 5071.6592 - val_mse: 5071.6592\n",
            "Epoch 130/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 358.8548 - mse: 358.8548 - val_loss: 5102.2188 - val_mse: 5102.2188\n",
            "Epoch 131/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 357.6107 - mse: 357.6107 - val_loss: 5094.2085 - val_mse: 5094.2085\n",
            "Epoch 132/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 356.4640 - mse: 356.4640 - val_loss: 5111.7422 - val_mse: 5111.7422\n",
            "Epoch 133/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 349.7950 - mse: 349.7950 - val_loss: 5041.1313 - val_mse: 5041.1313\n",
            "Epoch 134/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 351.8881 - mse: 351.8881 - val_loss: 5043.3594 - val_mse: 5043.3594\n",
            "Epoch 135/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 344.6157 - mse: 344.6157 - val_loss: 4984.0986 - val_mse: 4984.0986\n",
            "Epoch 136/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 345.2195 - mse: 345.2195 - val_loss: 4977.5283 - val_mse: 4977.5283\n",
            "Epoch 137/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 354.7838 - mse: 354.7838 - val_loss: 4856.8091 - val_mse: 4856.8091\n",
            "Epoch 138/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 340.6442 - mse: 340.6442 - val_loss: 4859.6592 - val_mse: 4859.6592\n",
            "Epoch 139/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 338.5199 - mse: 338.5199 - val_loss: 4856.5679 - val_mse: 4856.5679\n",
            "Epoch 140/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 339.1422 - mse: 339.1422 - val_loss: 4934.1025 - val_mse: 4934.1025\n",
            "Epoch 141/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 335.0578 - mse: 335.0578 - val_loss: 4950.9175 - val_mse: 4950.9175\n",
            "Epoch 142/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 330.9239 - mse: 330.9239 - val_loss: 4885.1338 - val_mse: 4885.1338\n",
            "Epoch 143/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 329.4187 - mse: 329.4187 - val_loss: 4836.0405 - val_mse: 4836.0405\n",
            "Epoch 144/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 331.5865 - mse: 331.5865 - val_loss: 4885.1729 - val_mse: 4885.1729\n",
            "Epoch 145/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 325.0028 - mse: 325.0028 - val_loss: 4827.0913 - val_mse: 4827.0913\n",
            "Epoch 146/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 322.5843 - mse: 322.5843 - val_loss: 4794.4126 - val_mse: 4794.4126\n",
            "Epoch 147/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 324.7103 - mse: 324.7103 - val_loss: 4737.2979 - val_mse: 4737.2979\n",
            "Epoch 148/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 325.5216 - mse: 325.5216 - val_loss: 4801.3052 - val_mse: 4801.3052\n",
            "Epoch 149/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 314.4691 - mse: 314.4691 - val_loss: 4780.7437 - val_mse: 4780.7437\n",
            "Epoch 150/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 314.9440 - mse: 314.9440 - val_loss: 4783.1719 - val_mse: 4783.1719\n",
            "Epoch 151/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 312.8086 - mse: 312.8086 - val_loss: 4715.9883 - val_mse: 4715.9883\n",
            "Epoch 152/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 313.2257 - mse: 313.2257 - val_loss: 4657.2598 - val_mse: 4657.2598\n",
            "Epoch 153/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 307.3191 - mse: 307.3191 - val_loss: 4654.0835 - val_mse: 4654.0835\n",
            "Epoch 154/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 309.4749 - mse: 309.4749 - val_loss: 4704.1353 - val_mse: 4704.1353\n",
            "Epoch 155/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 304.4969 - mse: 304.4969 - val_loss: 4660.0293 - val_mse: 4660.0293\n",
            "Epoch 156/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 302.4225 - mse: 302.4225 - val_loss: 4619.4932 - val_mse: 4619.4932\n",
            "Epoch 157/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 300.9963 - mse: 300.9963 - val_loss: 4590.9370 - val_mse: 4590.9370\n",
            "Epoch 158/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 298.8164 - mse: 298.8164 - val_loss: 4621.3984 - val_mse: 4621.3984\n",
            "Epoch 159/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 298.5529 - mse: 298.5529 - val_loss: 4674.4341 - val_mse: 4674.4341\n",
            "Epoch 160/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 294.4129 - mse: 294.4129 - val_loss: 4623.5791 - val_mse: 4623.5791\n",
            "Epoch 161/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 292.0361 - mse: 292.0361 - val_loss: 4613.0581 - val_mse: 4613.0581\n",
            "Epoch 162/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 291.7713 - mse: 291.7713 - val_loss: 4559.8760 - val_mse: 4559.8760\n",
            "Epoch 163/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 288.3923 - mse: 288.3923 - val_loss: 4524.1553 - val_mse: 4524.1553\n",
            "Epoch 164/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 288.1461 - mse: 288.1461 - val_loss: 4496.5146 - val_mse: 4496.5146\n",
            "Epoch 165/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 284.5052 - mse: 284.5052 - val_loss: 4483.5122 - val_mse: 4483.5122\n",
            "Epoch 166/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 286.9039 - mse: 286.9039 - val_loss: 4541.7646 - val_mse: 4541.7646\n",
            "Epoch 167/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 279.7924 - mse: 279.7924 - val_loss: 4529.8369 - val_mse: 4529.8369\n",
            "Epoch 168/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 285.4128 - mse: 285.4128 - val_loss: 4441.0532 - val_mse: 4441.0532\n",
            "Epoch 169/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 276.1400 - mse: 276.1400 - val_loss: 4434.7793 - val_mse: 4434.7793\n",
            "Epoch 170/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 273.6109 - mse: 273.6109 - val_loss: 4418.2422 - val_mse: 4418.2422\n",
            "Epoch 171/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 276.1936 - mse: 276.1936 - val_loss: 4382.5210 - val_mse: 4382.5210\n",
            "Epoch 172/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 270.9154 - mse: 270.9154 - val_loss: 4395.6719 - val_mse: 4395.6719\n",
            "Epoch 173/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 270.4862 - mse: 270.4862 - val_loss: 4404.8691 - val_mse: 4404.8691\n",
            "Epoch 174/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 269.2256 - mse: 269.2256 - val_loss: 4410.9165 - val_mse: 4410.9165\n",
            "Epoch 175/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 268.7345 - mse: 268.7345 - val_loss: 4342.2866 - val_mse: 4342.2866\n",
            "Epoch 176/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 262.9751 - mse: 262.9751 - val_loss: 4333.4604 - val_mse: 4333.4604\n",
            "Epoch 177/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 261.5755 - mse: 261.5755 - val_loss: 4316.0288 - val_mse: 4316.0288\n",
            "Epoch 178/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 262.9501 - mse: 262.9501 - val_loss: 4273.8110 - val_mse: 4273.8110\n",
            "Epoch 179/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 258.6992 - mse: 258.6992 - val_loss: 4257.3062 - val_mse: 4257.3062\n",
            "Epoch 180/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 261.4783 - mse: 261.4783 - val_loss: 4294.8369 - val_mse: 4294.8369\n",
            "Epoch 181/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 257.1901 - mse: 257.1901 - val_loss: 4289.7021 - val_mse: 4289.7021\n",
            "Epoch 182/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 257.0676 - mse: 257.0676 - val_loss: 4233.9214 - val_mse: 4233.9214\n",
            "Epoch 183/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 251.3903 - mse: 251.3903 - val_loss: 4223.0811 - val_mse: 4223.0811\n",
            "Epoch 184/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 255.7982 - mse: 255.7982 - val_loss: 4190.7041 - val_mse: 4190.7041\n",
            "Epoch 185/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 252.2327 - mse: 252.2327 - val_loss: 4209.3867 - val_mse: 4209.3867\n",
            "Epoch 186/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 245.9161 - mse: 245.9161 - val_loss: 4192.7788 - val_mse: 4192.7788\n",
            "Epoch 187/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 247.6725 - mse: 247.6725 - val_loss: 4180.9902 - val_mse: 4180.9902\n",
            "Epoch 188/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 244.5447 - mse: 244.5447 - val_loss: 4161.3262 - val_mse: 4161.3262\n",
            "Epoch 189/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 241.0821 - mse: 241.0821 - val_loss: 4137.9468 - val_mse: 4137.9468\n",
            "Epoch 190/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 240.9828 - mse: 240.9828 - val_loss: 4115.2173 - val_mse: 4115.2173\n",
            "Epoch 191/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 240.3498 - mse: 240.3498 - val_loss: 4111.5898 - val_mse: 4111.5898\n",
            "Epoch 192/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 236.4589 - mse: 236.4589 - val_loss: 4089.0474 - val_mse: 4089.0474\n",
            "Epoch 193/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 235.7419 - mse: 235.7419 - val_loss: 4073.4204 - val_mse: 4073.4204\n",
            "Epoch 194/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 234.5090 - mse: 234.5090 - val_loss: 4045.1135 - val_mse: 4045.1135\n",
            "Epoch 195/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 234.4721 - mse: 234.4721 - val_loss: 4020.2600 - val_mse: 4020.2600\n",
            "Epoch 196/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 232.6036 - mse: 232.6036 - val_loss: 4018.0391 - val_mse: 4018.0391\n",
            "Epoch 197/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 229.2834 - mse: 229.2834 - val_loss: 4007.9092 - val_mse: 4007.9092\n",
            "Epoch 198/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 230.4474 - mse: 230.4474 - val_loss: 3994.0972 - val_mse: 3994.0972\n",
            "Epoch 199/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 228.0390 - mse: 228.0390 - val_loss: 3972.9907 - val_mse: 3972.9907\n",
            "Epoch 200/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 225.8514 - mse: 225.8514 - val_loss: 3957.5200 - val_mse: 3957.5200\n",
            "Epoch 201/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 225.4532 - mse: 225.4532 - val_loss: 3954.4692 - val_mse: 3954.4692\n",
            "Epoch 202/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 226.0455 - mse: 226.0455 - val_loss: 3958.3833 - val_mse: 3958.3833\n",
            "Epoch 203/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 222.2860 - mse: 222.2860 - val_loss: 3924.3955 - val_mse: 3924.3955\n",
            "Epoch 204/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 219.3532 - mse: 219.3532 - val_loss: 3910.0603 - val_mse: 3910.0603\n",
            "Epoch 205/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 218.7387 - mse: 218.7387 - val_loss: 3902.8076 - val_mse: 3902.8076\n",
            "Epoch 206/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 221.0878 - mse: 221.0878 - val_loss: 3888.9114 - val_mse: 3888.9114\n",
            "Epoch 207/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 215.2617 - mse: 215.2617 - val_loss: 3879.1379 - val_mse: 3879.1379\n",
            "Epoch 208/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 213.8104 - mse: 213.8104 - val_loss: 3870.3154 - val_mse: 3870.3154\n",
            "Epoch 209/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 213.8508 - mse: 213.8508 - val_loss: 3863.6230 - val_mse: 3863.6230\n",
            "Epoch 210/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 216.3441 - mse: 216.3441 - val_loss: 3856.0581 - val_mse: 3856.0581\n",
            "Epoch 211/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 209.5127 - mse: 209.5127 - val_loss: 3836.9995 - val_mse: 3836.9995\n",
            "Epoch 212/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 211.5221 - mse: 211.5221 - val_loss: 3808.4971 - val_mse: 3808.4971\n",
            "Epoch 213/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 210.3346 - mse: 210.3346 - val_loss: 3800.2629 - val_mse: 3800.2629\n",
            "Epoch 214/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 206.5152 - mse: 206.5152 - val_loss: 3785.9219 - val_mse: 3785.9219\n",
            "Epoch 215/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 205.3580 - mse: 205.3580 - val_loss: 3775.2329 - val_mse: 3775.2329\n",
            "Epoch 216/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 204.4205 - mse: 204.4205 - val_loss: 3770.5723 - val_mse: 3770.5723\n",
            "Epoch 217/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 205.7741 - mse: 205.7741 - val_loss: 3755.1072 - val_mse: 3755.1072\n",
            "Epoch 218/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 200.7378 - mse: 200.7378 - val_loss: 3745.9468 - val_mse: 3745.9468\n",
            "Epoch 219/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 199.1492 - mse: 199.1492 - val_loss: 3737.6123 - val_mse: 3737.6123\n",
            "Epoch 220/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 201.8287 - mse: 201.8287 - val_loss: 3739.9915 - val_mse: 3739.9915\n",
            "Epoch 221/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 198.6422 - mse: 198.6422 - val_loss: 3717.1682 - val_mse: 3717.1682\n",
            "Epoch 222/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 197.8561 - mse: 197.8561 - val_loss: 3705.8823 - val_mse: 3705.8823\n",
            "Epoch 223/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 194.0358 - mse: 194.0358 - val_loss: 3693.9631 - val_mse: 3693.9631\n",
            "Epoch 224/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 194.0264 - mse: 194.0264 - val_loss: 3683.3147 - val_mse: 3683.3147\n",
            "Epoch 225/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 192.4201 - mse: 192.4201 - val_loss: 3668.0312 - val_mse: 3668.0312\n",
            "Epoch 226/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 190.7623 - mse: 190.7623 - val_loss: 3657.2981 - val_mse: 3657.2981\n",
            "Epoch 227/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 193.3744 - mse: 193.3744 - val_loss: 3652.1462 - val_mse: 3652.1462\n",
            "Epoch 228/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 191.4016 - mse: 191.4016 - val_loss: 3641.2571 - val_mse: 3641.2571\n",
            "Epoch 229/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 186.6900 - mse: 186.6900 - val_loss: 3631.2043 - val_mse: 3631.2043\n",
            "Epoch 230/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 190.7602 - mse: 190.7602 - val_loss: 3628.7288 - val_mse: 3628.7288\n",
            "Epoch 231/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 186.1622 - mse: 186.1622 - val_loss: 3607.4082 - val_mse: 3607.4082\n",
            "Epoch 232/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 183.2661 - mse: 183.2661 - val_loss: 3593.7715 - val_mse: 3593.7715\n",
            "Epoch 233/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 186.0878 - mse: 186.0878 - val_loss: 3588.4426 - val_mse: 3588.4426\n",
            "Epoch 234/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 180.6113 - mse: 180.6113 - val_loss: 3573.8955 - val_mse: 3573.8955\n",
            "Epoch 235/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 180.4188 - mse: 180.4188 - val_loss: 3563.0137 - val_mse: 3563.0137\n",
            "Epoch 236/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 180.2376 - mse: 180.2376 - val_loss: 3550.4902 - val_mse: 3550.4902\n",
            "Epoch 237/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 183.0499 - mse: 183.0499 - val_loss: 3554.6160 - val_mse: 3554.6160\n",
            "Epoch 238/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 176.9125 - mse: 176.9125 - val_loss: 3547.3418 - val_mse: 3547.3418\n",
            "Epoch 239/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 176.2562 - mse: 176.2562 - val_loss: 3542.8005 - val_mse: 3542.8005\n",
            "Epoch 240/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 178.9292 - mse: 178.9292 - val_loss: 3516.4802 - val_mse: 3516.4802\n",
            "Epoch 241/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 174.0534 - mse: 174.0534 - val_loss: 3510.4316 - val_mse: 3510.4316\n",
            "Epoch 242/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 178.0506 - mse: 178.0506 - val_loss: 3519.8887 - val_mse: 3519.8887\n",
            "Epoch 243/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 169.8309 - mse: 169.8309 - val_loss: 3500.5542 - val_mse: 3500.5542\n",
            "Epoch 244/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 169.5159 - mse: 169.5159 - val_loss: 3478.9302 - val_mse: 3478.9302\n",
            "Epoch 245/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 169.7802 - mse: 169.7802 - val_loss: 3456.7559 - val_mse: 3456.7559\n",
            "Epoch 246/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 169.9890 - mse: 169.9890 - val_loss: 3457.1428 - val_mse: 3457.1428\n",
            "Epoch 247/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 167.9574 - mse: 167.9574 - val_loss: 3444.0212 - val_mse: 3444.0212\n",
            "Epoch 248/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 169.1130 - mse: 169.1130 - val_loss: 3457.2161 - val_mse: 3457.2161\n",
            "Epoch 249/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 164.1089 - mse: 164.1089 - val_loss: 3450.8738 - val_mse: 3450.8738\n",
            "Epoch 250/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 168.3563 - mse: 168.3563 - val_loss: 3408.9089 - val_mse: 3408.9089\n",
            "Epoch 251/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 162.4031 - mse: 162.4031 - val_loss: 3412.0830 - val_mse: 3412.0830\n",
            "Epoch 252/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 162.3671 - mse: 162.3671 - val_loss: 3403.4512 - val_mse: 3403.4512\n",
            "Epoch 253/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 161.4144 - mse: 161.4144 - val_loss: 3387.6279 - val_mse: 3387.6279\n",
            "Epoch 254/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 160.4474 - mse: 160.4474 - val_loss: 3388.0239 - val_mse: 3388.0239\n",
            "Epoch 255/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 156.6191 - mse: 156.6191 - val_loss: 3387.0305 - val_mse: 3387.0305\n",
            "Epoch 256/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 156.0968 - mse: 156.0968 - val_loss: 3383.8374 - val_mse: 3383.8374\n",
            "Epoch 257/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 154.9961 - mse: 154.9961 - val_loss: 3383.0300 - val_mse: 3383.0300\n",
            "Epoch 258/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 155.0287 - mse: 155.0287 - val_loss: 3353.9482 - val_mse: 3353.9482\n",
            "Epoch 259/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 158.3243 - mse: 158.3243 - val_loss: 3370.7295 - val_mse: 3370.7295\n",
            "Epoch 260/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 152.7536 - mse: 152.7536 - val_loss: 3361.1611 - val_mse: 3361.1611\n",
            "Epoch 261/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 150.4521 - mse: 150.4521 - val_loss: 3319.9182 - val_mse: 3319.9182\n",
            "Epoch 262/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 148.9711 - mse: 148.9711 - val_loss: 3302.4653 - val_mse: 3302.4653\n",
            "Epoch 263/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 149.2412 - mse: 149.2412 - val_loss: 3300.6663 - val_mse: 3300.6663\n",
            "Epoch 264/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 147.7294 - mse: 147.7294 - val_loss: 3287.1641 - val_mse: 3287.1641\n",
            "Epoch 265/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 153.0885 - mse: 153.0885 - val_loss: 3328.0293 - val_mse: 3328.0293\n",
            "Epoch 266/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 145.7169 - mse: 145.7169 - val_loss: 3307.3770 - val_mse: 3307.3770\n",
            "Epoch 267/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 143.7915 - mse: 143.7915 - val_loss: 3284.2607 - val_mse: 3284.2607\n",
            "Epoch 268/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 143.7719 - mse: 143.7719 - val_loss: 3247.1074 - val_mse: 3247.1074\n",
            "Epoch 269/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 142.8358 - mse: 142.8358 - val_loss: 3255.5049 - val_mse: 3255.5049\n",
            "Epoch 270/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 145.6957 - mse: 145.6957 - val_loss: 3218.4717 - val_mse: 3218.4717\n",
            "Epoch 271/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 140.7610 - mse: 140.7610 - val_loss: 3231.2808 - val_mse: 3231.2808\n",
            "Epoch 272/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 150.7030 - mse: 150.7030 - val_loss: 3319.6685 - val_mse: 3319.6685\n",
            "Epoch 273/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 139.7579 - mse: 139.7579 - val_loss: 3288.9106 - val_mse: 3288.9106\n",
            "Epoch 274/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 138.4616 - mse: 138.4616 - val_loss: 3267.4590 - val_mse: 3267.4590\n",
            "Epoch 275/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 135.8966 - mse: 135.8966 - val_loss: 3240.9319 - val_mse: 3240.9319\n",
            "Epoch 276/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 135.9288 - mse: 135.9288 - val_loss: 3222.5659 - val_mse: 3222.5659\n",
            "Epoch 277/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 134.6340 - mse: 134.6340 - val_loss: 3200.9629 - val_mse: 3200.9629\n",
            "Epoch 278/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 133.6572 - mse: 133.6572 - val_loss: 3205.3628 - val_mse: 3205.3628\n",
            "Epoch 279/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 133.5120 - mse: 133.5120 - val_loss: 3173.9688 - val_mse: 3173.9688\n",
            "Epoch 280/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 131.1119 - mse: 131.1119 - val_loss: 3188.1938 - val_mse: 3188.1938\n",
            "Epoch 281/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 131.9707 - mse: 131.9707 - val_loss: 3163.0559 - val_mse: 3163.0559\n",
            "Epoch 282/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 132.5267 - mse: 132.5267 - val_loss: 3226.8757 - val_mse: 3226.8757\n",
            "Epoch 283/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 129.0033 - mse: 129.0033 - val_loss: 3218.3706 - val_mse: 3218.3706\n",
            "Epoch 284/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 127.7970 - mse: 127.7970 - val_loss: 3195.7764 - val_mse: 3195.7764\n",
            "Epoch 285/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 128.8734 - mse: 128.8734 - val_loss: 3209.3198 - val_mse: 3209.3198\n",
            "Epoch 286/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 130.8859 - mse: 130.8859 - val_loss: 3118.0061 - val_mse: 3118.0061\n",
            "Epoch 287/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 125.6964 - mse: 125.6964 - val_loss: 3132.0710 - val_mse: 3132.0710\n",
            "Epoch 288/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 125.4883 - mse: 125.4883 - val_loss: 3182.0398 - val_mse: 3182.0398\n",
            "Epoch 289/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 125.0421 - mse: 125.0421 - val_loss: 3202.0156 - val_mse: 3202.0156\n",
            "Epoch 290/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 123.9043 - mse: 123.9043 - val_loss: 3140.7896 - val_mse: 3140.7896\n",
            "Epoch 291/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 121.9660 - mse: 121.9660 - val_loss: 3116.4072 - val_mse: 3116.4072\n",
            "Epoch 292/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 120.3275 - mse: 120.3275 - val_loss: 3143.3457 - val_mse: 3143.3457\n",
            "Epoch 293/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 118.8931 - mse: 118.8931 - val_loss: 3158.6499 - val_mse: 3158.6499\n",
            "Epoch 294/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 121.3493 - mse: 121.3493 - val_loss: 3208.7593 - val_mse: 3208.7593\n",
            "Epoch 295/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 120.5738 - mse: 120.5738 - val_loss: 3107.8474 - val_mse: 3107.8474\n",
            "Epoch 296/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 115.8287 - mse: 115.8287 - val_loss: 3118.5012 - val_mse: 3118.5012\n",
            "Epoch 297/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 115.4734 - mse: 115.4734 - val_loss: 3109.4250 - val_mse: 3109.4250\n",
            "Epoch 298/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 117.1397 - mse: 117.1397 - val_loss: 3158.9702 - val_mse: 3158.9702\n",
            "Epoch 299/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 113.4060 - mse: 113.4060 - val_loss: 3164.6606 - val_mse: 3164.6606\n",
            "Epoch 300/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 112.8907 - mse: 112.8907 - val_loss: 3105.8105 - val_mse: 3105.8105\n",
            "Epoch 301/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 111.7579 - mse: 111.7579 - val_loss: 3107.8423 - val_mse: 3107.8423\n",
            "Epoch 302/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 110.5462 - mse: 110.5462 - val_loss: 3091.3110 - val_mse: 3091.3110\n",
            "Epoch 303/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 114.3258 - mse: 114.3258 - val_loss: 3032.8276 - val_mse: 3032.8276\n",
            "Epoch 304/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 107.5103 - mse: 107.5103 - val_loss: 3084.2852 - val_mse: 3084.2852\n",
            "Epoch 305/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 110.1700 - mse: 110.1700 - val_loss: 3163.0120 - val_mse: 3163.0120\n",
            "Epoch 306/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 109.3599 - mse: 109.3599 - val_loss: 3141.5063 - val_mse: 3141.5063\n",
            "Epoch 307/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 106.1670 - mse: 106.1670 - val_loss: 3088.4089 - val_mse: 3088.4089\n",
            "Epoch 308/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 105.1849 - mse: 105.1849 - val_loss: 3083.8481 - val_mse: 3083.8481\n",
            "Epoch 309/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 104.2667 - mse: 104.2667 - val_loss: 3053.0825 - val_mse: 3053.0825\n",
            "Epoch 310/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 104.8043 - mse: 104.8043 - val_loss: 3057.0146 - val_mse: 3057.0146\n",
            "Epoch 311/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 103.3472 - mse: 103.3472 - val_loss: 3062.0269 - val_mse: 3062.0269\n",
            "Epoch 312/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 102.7888 - mse: 102.7888 - val_loss: 3009.3018 - val_mse: 3009.3018\n",
            "Epoch 313/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 103.4477 - mse: 103.4477 - val_loss: 2982.2866 - val_mse: 2982.2866\n",
            "Epoch 314/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 100.9163 - mse: 100.9163 - val_loss: 3038.5654 - val_mse: 3038.5654\n",
            "Epoch 315/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 99.4285 - mse: 99.4285 - val_loss: 3077.6411 - val_mse: 3077.6411\n",
            "Epoch 316/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 100.0280 - mse: 100.0280 - val_loss: 3041.3274 - val_mse: 3041.3274\n",
            "Epoch 317/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 100.5046 - mse: 100.5046 - val_loss: 3006.4448 - val_mse: 3006.4448\n",
            "Epoch 318/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 95.8898 - mse: 95.8898 - val_loss: 3098.2466 - val_mse: 3098.2466\n",
            "Epoch 319/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 96.6535 - mse: 96.6535 - val_loss: 3144.9800 - val_mse: 3144.9800\n",
            "Epoch 320/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 96.5982 - mse: 96.5982 - val_loss: 3086.2847 - val_mse: 3086.2847\n",
            "Epoch 321/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 94.4424 - mse: 94.4424 - val_loss: 3065.9895 - val_mse: 3065.9895\n",
            "Epoch 322/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 95.1617 - mse: 95.1617 - val_loss: 3088.2371 - val_mse: 3088.2371\n",
            "Epoch 323/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 93.3149 - mse: 93.3149 - val_loss: 3041.2356 - val_mse: 3041.2356\n",
            "Epoch 324/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 94.3814 - mse: 94.3814 - val_loss: 2995.1877 - val_mse: 2995.1877\n",
            "Epoch 325/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 91.8623 - mse: 91.8623 - val_loss: 3050.6260 - val_mse: 3050.6260\n",
            "Epoch 326/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 91.1834 - mse: 91.1834 - val_loss: 3021.0830 - val_mse: 3021.0830\n",
            "Epoch 327/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 95.3205 - mse: 95.3205 - val_loss: 3144.1646 - val_mse: 3144.1646\n",
            "Epoch 328/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 89.5871 - mse: 89.5871 - val_loss: 3129.4390 - val_mse: 3129.4390\n",
            "Epoch 329/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 89.8756 - mse: 89.8756 - val_loss: 3022.2048 - val_mse: 3022.2048\n",
            "Epoch 330/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 87.3677 - mse: 87.3677 - val_loss: 3042.7629 - val_mse: 3042.7629\n",
            "Epoch 331/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 86.4922 - mse: 86.4922 - val_loss: 3051.1316 - val_mse: 3051.1316\n",
            "Epoch 332/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 86.3354 - mse: 86.3354 - val_loss: 3046.8113 - val_mse: 3046.8113\n",
            "Epoch 333/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 86.6740 - mse: 86.6740 - val_loss: 3009.6675 - val_mse: 3009.6675\n",
            "Epoch 334/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 85.0077 - mse: 85.0077 - val_loss: 3031.2551 - val_mse: 3031.2551\n",
            "Epoch 335/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 83.2743 - mse: 83.2743 - val_loss: 3081.3237 - val_mse: 3081.3237\n",
            "Epoch 336/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 83.6178 - mse: 83.6178 - val_loss: 3099.1812 - val_mse: 3099.1812\n",
            "Epoch 337/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 83.7198 - mse: 83.7198 - val_loss: 3019.7605 - val_mse: 3019.7605\n",
            "Epoch 338/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 81.2512 - mse: 81.2512 - val_loss: 3034.2754 - val_mse: 3034.2754\n",
            "Epoch 339/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 82.3381 - mse: 82.3381 - val_loss: 3020.7607 - val_mse: 3020.7607\n",
            "Epoch 340/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 79.8234 - mse: 79.8234 - val_loss: 3049.7949 - val_mse: 3049.7949\n",
            "Epoch 341/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 78.7739 - mse: 78.7739 - val_loss: 3126.1724 - val_mse: 3126.1724\n",
            "Epoch 342/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 78.5906 - mse: 78.5906 - val_loss: 3119.0762 - val_mse: 3119.0762\n",
            "Epoch 343/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 77.8725 - mse: 77.8725 - val_loss: 3067.7954 - val_mse: 3067.7954\n",
            "Epoch 344/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 77.9558 - mse: 77.9558 - val_loss: 3030.4023 - val_mse: 3030.4023\n",
            "Epoch 345/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 77.5199 - mse: 77.5199 - val_loss: 3034.1309 - val_mse: 3034.1309\n",
            "Epoch 346/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 75.3570 - mse: 75.3570 - val_loss: 3106.3738 - val_mse: 3106.3738\n",
            "Epoch 347/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 74.9945 - mse: 74.9945 - val_loss: 3117.9092 - val_mse: 3117.9092\n",
            "Epoch 348/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 74.9925 - mse: 74.9925 - val_loss: 3056.7417 - val_mse: 3056.7417\n",
            "Epoch 349/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 74.4693 - mse: 74.4693 - val_loss: 3096.2747 - val_mse: 3096.2747\n",
            "Epoch 350/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 74.6794 - mse: 74.6794 - val_loss: 3047.6167 - val_mse: 3047.6167\n",
            "Epoch 351/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 71.8597 - mse: 71.8597 - val_loss: 3088.2949 - val_mse: 3088.2949\n",
            "Epoch 352/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 71.5524 - mse: 71.5524 - val_loss: 3097.2742 - val_mse: 3097.2742\n",
            "Epoch 353/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 73.0543 - mse: 73.0543 - val_loss: 3165.2563 - val_mse: 3165.2563\n",
            "Epoch 354/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 70.1839 - mse: 70.1839 - val_loss: 3140.5208 - val_mse: 3140.5208\n",
            "Epoch 355/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 69.1482 - mse: 69.1482 - val_loss: 3058.3582 - val_mse: 3058.3582\n",
            "Epoch 356/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 69.6976 - mse: 69.6976 - val_loss: 3024.0154 - val_mse: 3024.0154\n",
            "Epoch 357/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 68.7519 - mse: 68.7519 - val_loss: 3023.8152 - val_mse: 3023.8152\n",
            "Epoch 358/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 69.9087 - mse: 69.9087 - val_loss: 2984.1785 - val_mse: 2984.1785\n",
            "Epoch 359/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 69.9659 - mse: 69.9659 - val_loss: 3129.7017 - val_mse: 3129.7017\n",
            "Epoch 360/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 67.6635 - mse: 67.6635 - val_loss: 3101.6816 - val_mse: 3101.6816\n",
            "Epoch 361/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 67.2939 - mse: 67.2939 - val_loss: 3165.2285 - val_mse: 3165.2285\n",
            "Epoch 362/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 65.4135 - mse: 65.4135 - val_loss: 3183.5049 - val_mse: 3183.5049\n",
            "Epoch 363/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 65.7275 - mse: 65.7275 - val_loss: 3186.6895 - val_mse: 3186.6895\n",
            "Epoch 364/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 64.7445 - mse: 64.7445 - val_loss: 3072.8599 - val_mse: 3072.8599\n",
            "Epoch 365/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 66.8058 - mse: 66.8058 - val_loss: 2989.5203 - val_mse: 2989.5203\n",
            "Epoch 366/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 63.5245 - mse: 63.5245 - val_loss: 3131.5312 - val_mse: 3131.5312\n",
            "Epoch 367/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 63.1672 - mse: 63.1672 - val_loss: 3188.3992 - val_mse: 3188.3992\n",
            "Epoch 368/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 61.1735 - mse: 61.1735 - val_loss: 3124.2559 - val_mse: 3124.2559\n",
            "Epoch 369/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 60.4831 - mse: 60.4831 - val_loss: 3109.6350 - val_mse: 3109.6350\n",
            "Epoch 370/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 61.2425 - mse: 61.2425 - val_loss: 3043.9866 - val_mse: 3043.9866\n",
            "Epoch 371/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 61.2442 - mse: 61.2442 - val_loss: 3149.9771 - val_mse: 3149.9771\n",
            "Epoch 372/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 59.4214 - mse: 59.4214 - val_loss: 3112.5496 - val_mse: 3112.5496\n",
            "Epoch 373/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 59.2562 - mse: 59.2562 - val_loss: 3125.5938 - val_mse: 3125.5938\n",
            "Epoch 374/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 59.9410 - mse: 59.9410 - val_loss: 3036.2424 - val_mse: 3036.2424\n",
            "Epoch 375/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 57.7995 - mse: 57.7995 - val_loss: 3107.0925 - val_mse: 3107.0925\n",
            "Epoch 376/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 58.4772 - mse: 58.4772 - val_loss: 3206.9089 - val_mse: 3206.9089\n",
            "Epoch 377/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 59.0759 - mse: 59.0759 - val_loss: 3113.1748 - val_mse: 3113.1748\n",
            "Epoch 378/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 55.7932 - mse: 55.7932 - val_loss: 3121.1826 - val_mse: 3121.1826\n",
            "Epoch 379/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 58.7102 - mse: 58.7102 - val_loss: 3230.9304 - val_mse: 3230.9304\n",
            "Epoch 380/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 55.2166 - mse: 55.2166 - val_loss: 3181.3542 - val_mse: 3181.3542\n",
            "Epoch 381/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 54.6700 - mse: 54.6700 - val_loss: 3129.8076 - val_mse: 3129.8076\n",
            "Epoch 382/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 53.8939 - mse: 53.8939 - val_loss: 3147.9744 - val_mse: 3147.9744\n",
            "Epoch 383/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 53.2016 - mse: 53.2016 - val_loss: 3143.0127 - val_mse: 3143.0127\n",
            "Epoch 384/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 53.3476 - mse: 53.3476 - val_loss: 3110.9922 - val_mse: 3110.9922\n",
            "Epoch 385/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 53.3328 - mse: 53.3328 - val_loss: 3150.7002 - val_mse: 3150.7002\n",
            "Epoch 386/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 52.2706 - mse: 52.2706 - val_loss: 3177.6316 - val_mse: 3177.6316\n",
            "Epoch 387/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 51.7372 - mse: 51.7372 - val_loss: 3261.5405 - val_mse: 3261.5405\n",
            "Epoch 388/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 52.1065 - mse: 52.1065 - val_loss: 3250.2698 - val_mse: 3250.2698\n",
            "Epoch 389/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 50.8230 - mse: 50.8230 - val_loss: 3198.5474 - val_mse: 3198.5474\n",
            "Epoch 390/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 50.5794 - mse: 50.5794 - val_loss: 3160.7878 - val_mse: 3160.7878\n",
            "Epoch 391/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 50.2019 - mse: 50.2019 - val_loss: 3152.6997 - val_mse: 3152.6997\n",
            "Epoch 392/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 50.0979 - mse: 50.0979 - val_loss: 3283.2605 - val_mse: 3283.2605\n",
            "Epoch 393/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 49.7222 - mse: 49.7222 - val_loss: 3210.6838 - val_mse: 3210.6838\n",
            "Epoch 394/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 48.2454 - mse: 48.2454 - val_loss: 3224.0681 - val_mse: 3224.0681\n",
            "Epoch 395/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 47.3315 - mse: 47.3315 - val_loss: 3241.5234 - val_mse: 3241.5234\n",
            "Epoch 396/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 47.4937 - mse: 47.4937 - val_loss: 3205.6965 - val_mse: 3205.6965\n",
            "Epoch 397/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 46.9375 - mse: 46.9375 - val_loss: 3257.5688 - val_mse: 3257.5688\n",
            "Epoch 398/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 46.4953 - mse: 46.4953 - val_loss: 3223.3486 - val_mse: 3223.3486\n",
            "Epoch 399/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 46.0944 - mse: 46.0945 - val_loss: 3158.3247 - val_mse: 3158.3247\n",
            "Epoch 400/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 44.9655 - mse: 44.9655 - val_loss: 3174.8474 - val_mse: 3174.8474\n",
            "Epoch 401/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 45.1122 - mse: 45.1122 - val_loss: 3214.8203 - val_mse: 3214.8203\n",
            "Epoch 402/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 45.4861 - mse: 45.4861 - val_loss: 3254.1760 - val_mse: 3254.1760\n",
            "Epoch 403/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 45.0309 - mse: 45.0309 - val_loss: 3178.7678 - val_mse: 3178.7678\n",
            "Epoch 404/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 43.8212 - mse: 43.8212 - val_loss: 3280.2180 - val_mse: 3280.2180\n",
            "Epoch 405/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 43.4607 - mse: 43.4607 - val_loss: 3268.4160 - val_mse: 3268.4160\n",
            "Epoch 406/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 42.6950 - mse: 42.6950 - val_loss: 3229.3777 - val_mse: 3229.3777\n",
            "Epoch 407/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 42.0508 - mse: 42.0508 - val_loss: 3214.1270 - val_mse: 3214.1270\n",
            "Epoch 408/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 42.0309 - mse: 42.0309 - val_loss: 3219.2605 - val_mse: 3219.2605\n",
            "Epoch 409/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 42.2160 - mse: 42.2160 - val_loss: 3186.6567 - val_mse: 3186.6567\n",
            "Epoch 410/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 41.1079 - mse: 41.1079 - val_loss: 3312.2200 - val_mse: 3312.2200\n",
            "Epoch 411/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 42.9370 - mse: 42.9370 - val_loss: 3388.8113 - val_mse: 3388.8113\n",
            "Epoch 412/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 40.3530 - mse: 40.3530 - val_loss: 3266.2344 - val_mse: 3266.2344\n",
            "Epoch 413/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 42.3096 - mse: 42.3096 - val_loss: 3185.5142 - val_mse: 3185.5142\n",
            "Epoch 414/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 39.7441 - mse: 39.7441 - val_loss: 3310.8315 - val_mse: 3310.8315\n",
            "Epoch 415/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 38.9197 - mse: 38.9197 - val_loss: 3304.1987 - val_mse: 3304.1987\n",
            "Epoch 416/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 38.5139 - mse: 38.5139 - val_loss: 3300.1243 - val_mse: 3300.1243\n",
            "Epoch 417/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 40.2067 - mse: 40.2067 - val_loss: 3176.5505 - val_mse: 3176.5505\n",
            "Epoch 418/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 39.0216 - mse: 39.0216 - val_loss: 3328.5063 - val_mse: 3328.5063\n",
            "Epoch 419/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 37.5148 - mse: 37.5148 - val_loss: 3296.1472 - val_mse: 3296.1472\n",
            "Epoch 420/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 37.1150 - mse: 37.1150 - val_loss: 3296.3098 - val_mse: 3296.3098\n",
            "Epoch 421/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 36.7788 - mse: 36.7788 - val_loss: 3269.4624 - val_mse: 3269.4624\n",
            "Epoch 422/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 36.3216 - mse: 36.3216 - val_loss: 3361.2292 - val_mse: 3361.2292\n",
            "Epoch 423/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 35.8972 - mse: 35.8972 - val_loss: 3327.1323 - val_mse: 3327.1323\n",
            "Epoch 424/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 35.4043 - mse: 35.4043 - val_loss: 3308.9695 - val_mse: 3308.9695\n",
            "Epoch 425/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 34.7508 - mse: 34.7508 - val_loss: 3310.8018 - val_mse: 3310.8018\n",
            "Epoch 426/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 34.3931 - mse: 34.3931 - val_loss: 3250.5334 - val_mse: 3250.5334\n",
            "Epoch 427/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 34.1904 - mse: 34.1904 - val_loss: 3233.7903 - val_mse: 3233.7903\n",
            "Epoch 428/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 36.0155 - mse: 36.0155 - val_loss: 3195.7246 - val_mse: 3195.7246\n",
            "Epoch 429/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 34.6633 - mse: 34.6633 - val_loss: 3370.7207 - val_mse: 3370.7207\n",
            "Epoch 430/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 33.1269 - mse: 33.1269 - val_loss: 3325.5669 - val_mse: 3325.5669\n",
            "Epoch 431/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 33.2920 - mse: 33.2920 - val_loss: 3378.0710 - val_mse: 3378.0710\n",
            "Epoch 432/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 33.0489 - mse: 33.0489 - val_loss: 3283.7656 - val_mse: 3283.7656\n",
            "Epoch 433/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 32.0423 - mse: 32.0423 - val_loss: 3303.2537 - val_mse: 3303.2537\n",
            "Epoch 434/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 32.2362 - mse: 32.2362 - val_loss: 3339.5510 - val_mse: 3339.5510\n",
            "Epoch 435/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 32.1692 - mse: 32.1692 - val_loss: 3261.5632 - val_mse: 3261.5632\n",
            "Epoch 436/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 31.3941 - mse: 31.3941 - val_loss: 3371.4346 - val_mse: 3371.4346\n",
            "Epoch 437/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 30.8830 - mse: 30.8830 - val_loss: 3381.4646 - val_mse: 3381.4646\n",
            "Epoch 438/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 30.4132 - mse: 30.4132 - val_loss: 3342.8013 - val_mse: 3342.8013\n",
            "Epoch 439/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 30.6404 - mse: 30.6404 - val_loss: 3301.8130 - val_mse: 3301.8130\n",
            "Epoch 440/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 29.5042 - mse: 29.5042 - val_loss: 3348.0212 - val_mse: 3348.0212\n",
            "Epoch 441/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 29.8445 - mse: 29.8445 - val_loss: 3330.9419 - val_mse: 3330.9419\n",
            "Epoch 442/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 32.0226 - mse: 32.0226 - val_loss: 3469.1003 - val_mse: 3469.1003\n",
            "Epoch 443/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 29.0958 - mse: 29.0958 - val_loss: 3330.1023 - val_mse: 3330.1023\n",
            "Epoch 444/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 31.0938 - mse: 31.0938 - val_loss: 3186.6489 - val_mse: 3186.6489\n",
            "Epoch 445/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 28.5335 - mse: 28.5335 - val_loss: 3282.1028 - val_mse: 3282.1028\n",
            "Epoch 446/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 28.2984 - mse: 28.2984 - val_loss: 3431.1316 - val_mse: 3431.1316\n",
            "Epoch 447/1000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 29.1275 - mse: 29.1275 - val_loss: 3465.9048 - val_mse: 3465.9048\n",
            "Epoch 448/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 27.7039 - mse: 27.7039 - val_loss: 3375.6519 - val_mse: 3375.6519\n",
            "Epoch 449/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 26.8782 - mse: 26.8782 - val_loss: 3366.6074 - val_mse: 3366.6074\n",
            "Epoch 450/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 27.0116 - mse: 27.0116 - val_loss: 3403.7671 - val_mse: 3403.7671\n",
            "Epoch 451/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 26.3352 - mse: 26.3352 - val_loss: 3344.8403 - val_mse: 3344.8403\n",
            "Epoch 452/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 26.3524 - mse: 26.3524 - val_loss: 3336.9395 - val_mse: 3336.9395\n",
            "Epoch 453/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 25.8296 - mse: 25.8296 - val_loss: 3347.0122 - val_mse: 3347.0122\n",
            "Epoch 454/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 26.9937 - mse: 26.9937 - val_loss: 3287.0112 - val_mse: 3287.0112\n",
            "Epoch 455/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 25.4799 - mse: 25.4799 - val_loss: 3415.2505 - val_mse: 3415.2505\n",
            "Epoch 456/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 25.8592 - mse: 25.8592 - val_loss: 3478.4622 - val_mse: 3478.4622\n",
            "Epoch 457/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 24.9060 - mse: 24.9060 - val_loss: 3385.6443 - val_mse: 3385.6443\n",
            "Epoch 458/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 25.1429 - mse: 25.1429 - val_loss: 3359.1440 - val_mse: 3359.1440\n",
            "Epoch 459/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 24.6200 - mse: 24.6200 - val_loss: 3374.9646 - val_mse: 3374.9646\n",
            "Epoch 460/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 24.7495 - mse: 24.7495 - val_loss: 3453.7507 - val_mse: 3453.7507\n",
            "Epoch 461/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 24.3822 - mse: 24.3822 - val_loss: 3434.8452 - val_mse: 3434.8452\n",
            "Epoch 462/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 23.4085 - mse: 23.4085 - val_loss: 3344.2812 - val_mse: 3344.2812\n",
            "Epoch 463/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 24.1423 - mse: 24.1423 - val_loss: 3365.3552 - val_mse: 3365.3552\n",
            "Epoch 464/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 23.0885 - mse: 23.0885 - val_loss: 3360.7207 - val_mse: 3360.7207\n",
            "Epoch 465/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.2219 - mse: 23.2219 - val_loss: 3346.3296 - val_mse: 3346.3296\n",
            "Epoch 466/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.6361 - mse: 22.6361 - val_loss: 3347.0591 - val_mse: 3347.0591\n",
            "Epoch 467/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.4379 - mse: 22.4379 - val_loss: 3360.0247 - val_mse: 3360.0247\n",
            "Epoch 468/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.7840 - mse: 22.7840 - val_loss: 3306.6184 - val_mse: 3306.6184\n",
            "Epoch 469/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.1053 - mse: 22.1053 - val_loss: 3415.6074 - val_mse: 3415.6074\n",
            "Epoch 470/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.1708 - mse: 22.1708 - val_loss: 3476.5647 - val_mse: 3476.5647\n",
            "Epoch 471/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 21.6185 - mse: 21.6185 - val_loss: 3443.3713 - val_mse: 3443.3713\n",
            "Epoch 472/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 22.1661 - mse: 22.1661 - val_loss: 3379.5527 - val_mse: 3379.5527\n",
            "Epoch 473/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 21.9604 - mse: 21.9604 - val_loss: 3482.4814 - val_mse: 3482.4814\n",
            "Epoch 474/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 20.9308 - mse: 20.9308 - val_loss: 3437.5005 - val_mse: 3437.5005\n",
            "Epoch 475/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 21.7309 - mse: 21.7309 - val_loss: 3351.1418 - val_mse: 3351.1418\n",
            "Epoch 476/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 20.3316 - mse: 20.3316 - val_loss: 3423.8494 - val_mse: 3423.8494\n",
            "Epoch 477/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 20.6452 - mse: 20.6452 - val_loss: 3399.7402 - val_mse: 3399.7402\n",
            "Epoch 478/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 20.2128 - mse: 20.2128 - val_loss: 3417.9609 - val_mse: 3417.9609\n",
            "Epoch 479/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 20.2103 - mse: 20.2103 - val_loss: 3467.5342 - val_mse: 3467.5342\n",
            "Epoch 480/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 19.7483 - mse: 19.7483 - val_loss: 3440.9312 - val_mse: 3440.9312\n",
            "Epoch 481/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 20.2012 - mse: 20.2012 - val_loss: 3352.9241 - val_mse: 3352.9241\n",
            "Epoch 482/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 19.5761 - mse: 19.5761 - val_loss: 3459.3450 - val_mse: 3459.3450\n",
            "Epoch 483/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 19.7778 - mse: 19.7778 - val_loss: 3523.8069 - val_mse: 3523.8069\n",
            "Epoch 484/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 19.1634 - mse: 19.1634 - val_loss: 3422.1724 - val_mse: 3422.1724\n",
            "Epoch 485/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 19.2624 - mse: 19.2624 - val_loss: 3389.1323 - val_mse: 3389.1323\n",
            "Epoch 486/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 18.7850 - mse: 18.7850 - val_loss: 3419.8965 - val_mse: 3419.8965\n",
            "Epoch 487/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 19.0361 - mse: 19.0361 - val_loss: 3426.3501 - val_mse: 3426.3501\n",
            "Epoch 488/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 18.2734 - mse: 18.2734 - val_loss: 3477.7480 - val_mse: 3477.7480\n",
            "Epoch 489/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 19.0621 - mse: 19.0621 - val_loss: 3541.9922 - val_mse: 3541.9922\n",
            "Epoch 490/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 18.2274 - mse: 18.2274 - val_loss: 3418.3879 - val_mse: 3418.3879\n",
            "Epoch 491/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 18.0238 - mse: 18.0238 - val_loss: 3381.1589 - val_mse: 3381.1589\n",
            "Epoch 492/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 18.2417 - mse: 18.2417 - val_loss: 3361.7209 - val_mse: 3361.7209\n",
            "Epoch 493/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 17.8079 - mse: 17.8079 - val_loss: 3488.3359 - val_mse: 3488.3359\n",
            "Epoch 494/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 17.4921 - mse: 17.4921 - val_loss: 3506.1675 - val_mse: 3506.1675\n",
            "Epoch 495/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 17.5026 - mse: 17.5026 - val_loss: 3433.3721 - val_mse: 3433.3721\n",
            "Epoch 496/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 17.2743 - mse: 17.2743 - val_loss: 3477.6833 - val_mse: 3477.6833\n",
            "Epoch 497/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 16.9214 - mse: 16.9214 - val_loss: 3467.5073 - val_mse: 3467.5073\n",
            "Epoch 498/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 16.8757 - mse: 16.8757 - val_loss: 3449.6863 - val_mse: 3449.6863\n",
            "Epoch 499/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 16.6564 - mse: 16.6564 - val_loss: 3507.2144 - val_mse: 3507.2144\n",
            "Epoch 500/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 16.9132 - mse: 16.9132 - val_loss: 3418.0071 - val_mse: 3418.0071\n",
            "Epoch 501/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 17.5412 - mse: 17.5412 - val_loss: 3560.0518 - val_mse: 3560.0518\n",
            "Epoch 502/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 16.1997 - mse: 16.1997 - val_loss: 3465.6633 - val_mse: 3465.6633\n",
            "Epoch 503/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 16.4421 - mse: 16.4421 - val_loss: 3416.8801 - val_mse: 3416.8801\n",
            "Epoch 504/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 16.6579 - mse: 16.6579 - val_loss: 3584.6667 - val_mse: 3584.6667\n",
            "Epoch 505/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.8361 - mse: 15.8361 - val_loss: 3587.6946 - val_mse: 3587.6946\n",
            "Epoch 506/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.5756 - mse: 15.5756 - val_loss: 3523.3481 - val_mse: 3523.3481\n",
            "Epoch 507/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.8048 - mse: 15.8048 - val_loss: 3495.7939 - val_mse: 3495.7939\n",
            "Epoch 508/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.9066 - mse: 15.9066 - val_loss: 3635.7422 - val_mse: 3635.7422\n",
            "Epoch 509/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.3885 - mse: 15.3885 - val_loss: 3563.6777 - val_mse: 3563.6777\n",
            "Epoch 510/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 15.9198 - mse: 15.9198 - val_loss: 3511.8528 - val_mse: 3511.8528\n",
            "Epoch 511/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 15.0283 - mse: 15.0283 - val_loss: 3587.4524 - val_mse: 3587.4524\n",
            "Epoch 512/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 14.8389 - mse: 14.8389 - val_loss: 3624.8318 - val_mse: 3624.8318\n",
            "Epoch 513/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 15.3332 - mse: 15.3332 - val_loss: 3675.2363 - val_mse: 3675.2363\n",
            "Epoch 514/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 15.0550 - mse: 15.0550 - val_loss: 3553.1870 - val_mse: 3553.1870\n",
            "Epoch 515/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 14.7887 - mse: 14.7887 - val_loss: 3543.6980 - val_mse: 3543.6980\n",
            "Epoch 516/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 15.1275 - mse: 15.1275 - val_loss: 3711.1143 - val_mse: 3711.1143\n",
            "Epoch 517/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 14.2546 - mse: 14.2546 - val_loss: 3615.1230 - val_mse: 3615.1230\n",
            "Epoch 518/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 14.7736 - mse: 14.7736 - val_loss: 3558.9111 - val_mse: 3558.9111\n",
            "Epoch 519/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.6740 - mse: 13.6740 - val_loss: 3603.5559 - val_mse: 3603.5559\n",
            "Epoch 520/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 14.0977 - mse: 14.0977 - val_loss: 3595.3928 - val_mse: 3595.3928\n",
            "Epoch 521/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.8408 - mse: 13.8408 - val_loss: 3548.9644 - val_mse: 3548.9644\n",
            "Epoch 522/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.5449 - mse: 13.5449 - val_loss: 3502.5432 - val_mse: 3502.5432\n",
            "Epoch 523/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 13.4743 - mse: 13.4743 - val_loss: 3529.9866 - val_mse: 3529.9866\n",
            "Epoch 524/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.2809 - mse: 13.2809 - val_loss: 3619.2266 - val_mse: 3619.2266\n",
            "Epoch 525/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.7986 - mse: 13.7986 - val_loss: 3514.7964 - val_mse: 3514.7964\n",
            "Epoch 526/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.9907 - mse: 12.9907 - val_loss: 3527.5703 - val_mse: 3527.5703\n",
            "Epoch 527/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.1575 - mse: 13.1575 - val_loss: 3509.0034 - val_mse: 3509.0034\n",
            "Epoch 528/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 13.5886 - mse: 13.5886 - val_loss: 3627.8757 - val_mse: 3627.8757\n",
            "Epoch 529/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.8527 - mse: 12.8527 - val_loss: 3585.3281 - val_mse: 3585.3281\n",
            "Epoch 530/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.6383 - mse: 12.6383 - val_loss: 3577.2373 - val_mse: 3577.2373\n",
            "Epoch 531/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.8512 - mse: 12.8512 - val_loss: 3616.1704 - val_mse: 3616.1704\n",
            "Epoch 532/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.2879 - mse: 12.2879 - val_loss: 3525.7329 - val_mse: 3525.7329\n",
            "Epoch 533/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 12.8959 - mse: 12.8959 - val_loss: 3456.9346 - val_mse: 3456.9346\n",
            "Epoch 534/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.2930 - mse: 12.2930 - val_loss: 3572.2969 - val_mse: 3572.2969\n",
            "Epoch 535/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.0587 - mse: 12.0587 - val_loss: 3606.9575 - val_mse: 3606.9575\n",
            "Epoch 536/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.8320 - mse: 12.8320 - val_loss: 3515.3354 - val_mse: 3515.3354\n",
            "Epoch 537/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.9192 - mse: 11.9192 - val_loss: 3583.8152 - val_mse: 3583.8152\n",
            "Epoch 538/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 12.2262 - mse: 12.2262 - val_loss: 3573.2073 - val_mse: 3573.2073\n",
            "Epoch 539/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.7557 - mse: 11.7557 - val_loss: 3536.2817 - val_mse: 3536.2817\n",
            "Epoch 540/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 12.3317 - mse: 12.3317 - val_loss: 3599.2651 - val_mse: 3599.2651\n",
            "Epoch 541/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 12.1706 - mse: 12.1706 - val_loss: 3477.6143 - val_mse: 3477.6143\n",
            "Epoch 542/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 12.3333 - mse: 12.3333 - val_loss: 3495.9148 - val_mse: 3495.9148\n",
            "Epoch 543/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 11.9486 - mse: 11.9486 - val_loss: 3629.9224 - val_mse: 3629.9224\n",
            "Epoch 544/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.6014 - mse: 11.6014 - val_loss: 3531.8120 - val_mse: 3531.8120\n",
            "Epoch 545/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.1785 - mse: 11.1785 - val_loss: 3444.2407 - val_mse: 3444.2407\n",
            "Epoch 546/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.3315 - mse: 11.3315 - val_loss: 3471.3181 - val_mse: 3471.3181\n",
            "Epoch 547/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 11.0344 - mse: 11.0344 - val_loss: 3609.9106 - val_mse: 3609.9106\n",
            "Epoch 548/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 11.0274 - mse: 11.0274 - val_loss: 3586.5376 - val_mse: 3586.5376\n",
            "Epoch 549/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.8587 - mse: 10.8587 - val_loss: 3513.6333 - val_mse: 3513.6333\n",
            "Epoch 550/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.9190 - mse: 10.9190 - val_loss: 3514.4985 - val_mse: 3514.4985\n",
            "Epoch 551/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.9778 - mse: 10.9778 - val_loss: 3544.6582 - val_mse: 3544.6582\n",
            "Epoch 552/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 11.3012 - mse: 11.3012 - val_loss: 3443.2202 - val_mse: 3443.2202\n",
            "Epoch 553/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 10.7827 - mse: 10.7827 - val_loss: 3647.9766 - val_mse: 3647.9766\n",
            "Epoch 554/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 10.6541 - mse: 10.6541 - val_loss: 3596.0242 - val_mse: 3596.0242\n",
            "Epoch 555/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.3223 - mse: 10.3223 - val_loss: 3557.9197 - val_mse: 3557.9197\n",
            "Epoch 556/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.2185 - mse: 10.2185 - val_loss: 3510.7883 - val_mse: 3510.7883\n",
            "Epoch 557/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.2293 - mse: 10.2293 - val_loss: 3501.6724 - val_mse: 3501.6724\n",
            "Epoch 558/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 10.1179 - mse: 10.1179 - val_loss: 3512.4653 - val_mse: 3512.4653\n",
            "Epoch 559/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.5997 - mse: 10.5997 - val_loss: 3573.1440 - val_mse: 3573.1440\n",
            "Epoch 560/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 10.0346 - mse: 10.0346 - val_loss: 3508.7708 - val_mse: 3508.7708\n",
            "Epoch 561/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.8808 - mse: 9.8808 - val_loss: 3472.5078 - val_mse: 3472.5078\n",
            "Epoch 562/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.8782 - mse: 9.8782 - val_loss: 3520.9807 - val_mse: 3520.9807\n",
            "Epoch 563/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.7186 - mse: 9.7186 - val_loss: 3517.5051 - val_mse: 3517.5051\n",
            "Epoch 564/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.8528 - mse: 9.8528 - val_loss: 3519.5986 - val_mse: 3519.5986\n",
            "Epoch 565/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.6794 - mse: 9.6794 - val_loss: 3570.4832 - val_mse: 3570.4832\n",
            "Epoch 566/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.7116 - mse: 9.7116 - val_loss: 3475.1741 - val_mse: 3475.1741\n",
            "Epoch 567/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.4724 - mse: 9.4724 - val_loss: 3507.2117 - val_mse: 3507.2117\n",
            "Epoch 568/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.4699 - mse: 9.4699 - val_loss: 3611.4766 - val_mse: 3611.4766\n",
            "Epoch 569/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.6833 - mse: 9.6833 - val_loss: 3536.5005 - val_mse: 3536.5005\n",
            "Epoch 570/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.4223 - mse: 9.4223 - val_loss: 3474.9966 - val_mse: 3474.9966\n",
            "Epoch 571/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.3526 - mse: 9.3526 - val_loss: 3590.9958 - val_mse: 3590.9958\n",
            "Epoch 572/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.6264 - mse: 9.6264 - val_loss: 3639.0142 - val_mse: 3639.0142\n",
            "Epoch 573/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.3151 - mse: 9.3151 - val_loss: 3487.9937 - val_mse: 3487.9937\n",
            "Epoch 574/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.2725 - mse: 9.2725 - val_loss: 3572.8660 - val_mse: 3572.8660\n",
            "Epoch 575/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.0434 - mse: 9.0434 - val_loss: 3585.6472 - val_mse: 3585.6472\n",
            "Epoch 576/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.0086 - mse: 9.0086 - val_loss: 3573.4255 - val_mse: 3573.4255\n",
            "Epoch 577/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 9.3441 - mse: 9.3441 - val_loss: 3579.6926 - val_mse: 3579.6926\n",
            "Epoch 578/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.9292 - mse: 8.9292 - val_loss: 3612.3052 - val_mse: 3612.3052\n",
            "Epoch 579/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 8.8232 - mse: 8.8232 - val_loss: 3601.5833 - val_mse: 3601.5833\n",
            "Epoch 580/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.6990 - mse: 8.6990 - val_loss: 3546.7019 - val_mse: 3546.7019\n",
            "Epoch 581/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.4678 - mse: 8.4678 - val_loss: 3562.0840 - val_mse: 3562.0840\n",
            "Epoch 582/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.7097 - mse: 8.7097 - val_loss: 3547.6030 - val_mse: 3547.6030\n",
            "Epoch 583/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.3847 - mse: 8.3847 - val_loss: 3566.3730 - val_mse: 3566.3730\n",
            "Epoch 584/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.4695 - mse: 8.4695 - val_loss: 3610.3154 - val_mse: 3610.3154\n",
            "Epoch 585/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.6658 - mse: 8.6658 - val_loss: 3482.0325 - val_mse: 3482.0325\n",
            "Epoch 586/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.4891 - mse: 8.4891 - val_loss: 3549.0186 - val_mse: 3549.0186\n",
            "Epoch 587/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 8.3632 - mse: 8.3632 - val_loss: 3597.8308 - val_mse: 3597.8308\n",
            "Epoch 588/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.1666 - mse: 8.1666 - val_loss: 3584.4160 - val_mse: 3584.4160\n",
            "Epoch 589/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.1167 - mse: 8.1167 - val_loss: 3528.9622 - val_mse: 3528.9622\n",
            "Epoch 590/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.0486 - mse: 8.0486 - val_loss: 3522.5171 - val_mse: 3522.5171\n",
            "Epoch 591/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.2333 - mse: 8.2333 - val_loss: 3542.7031 - val_mse: 3542.7031\n",
            "Epoch 592/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.0909 - mse: 8.0909 - val_loss: 3553.5498 - val_mse: 3553.5498\n",
            "Epoch 593/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.9593 - mse: 7.9593 - val_loss: 3545.7722 - val_mse: 3545.7722\n",
            "Epoch 594/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 8.0066 - mse: 8.0066 - val_loss: 3588.9880 - val_mse: 3588.9880\n",
            "Epoch 595/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.0451 - mse: 8.0451 - val_loss: 3545.9729 - val_mse: 3545.9729\n",
            "Epoch 596/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.8253 - mse: 7.8253 - val_loss: 3611.5286 - val_mse: 3611.5286\n",
            "Epoch 597/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 8.3289 - mse: 8.3289 - val_loss: 3711.9902 - val_mse: 3711.9902\n",
            "Epoch 598/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.4804 - mse: 7.4804 - val_loss: 3540.2847 - val_mse: 3540.2847\n",
            "Epoch 599/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.6000 - mse: 7.6000 - val_loss: 3540.1021 - val_mse: 3540.1021\n",
            "Epoch 600/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.4204 - mse: 7.4204 - val_loss: 3615.4458 - val_mse: 3615.4458\n",
            "Epoch 601/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.6798 - mse: 7.6798 - val_loss: 3614.9702 - val_mse: 3614.9702\n",
            "Epoch 602/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.3818 - mse: 7.3818 - val_loss: 3643.5447 - val_mse: 3643.5447\n",
            "Epoch 603/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.2686 - mse: 7.2686 - val_loss: 3643.3877 - val_mse: 3643.3877\n",
            "Epoch 604/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.5292 - mse: 7.5292 - val_loss: 3546.6924 - val_mse: 3546.6924\n",
            "Epoch 605/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.2530 - mse: 7.2530 - val_loss: 3547.2981 - val_mse: 3547.2981\n",
            "Epoch 606/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.4976 - mse: 7.4976 - val_loss: 3600.8972 - val_mse: 3600.8972\n",
            "Epoch 607/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.9680 - mse: 6.9680 - val_loss: 3512.4700 - val_mse: 3512.4700\n",
            "Epoch 608/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.3497 - mse: 7.3497 - val_loss: 3518.8303 - val_mse: 3518.8303\n",
            "Epoch 609/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.0585 - mse: 7.0585 - val_loss: 3640.3215 - val_mse: 3640.3215\n",
            "Epoch 610/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.0665 - mse: 7.0665 - val_loss: 3553.5894 - val_mse: 3553.5894\n",
            "Epoch 611/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.8019 - mse: 6.8019 - val_loss: 3553.4858 - val_mse: 3553.4858\n",
            "Epoch 612/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.8735 - mse: 6.8735 - val_loss: 3603.1458 - val_mse: 3603.1458\n",
            "Epoch 613/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.7750 - mse: 6.7750 - val_loss: 3540.5972 - val_mse: 3540.5972\n",
            "Epoch 614/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.6897 - mse: 7.6897 - val_loss: 3527.3999 - val_mse: 3527.3999\n",
            "Epoch 615/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 7.4027 - mse: 7.4027 - val_loss: 3737.2329 - val_mse: 3737.2329\n",
            "Epoch 616/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.5771 - mse: 6.5771 - val_loss: 3573.0886 - val_mse: 3573.0886\n",
            "Epoch 617/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.6578 - mse: 6.6578 - val_loss: 3538.9448 - val_mse: 3538.9448\n",
            "Epoch 618/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.5810 - mse: 6.5810 - val_loss: 3602.4602 - val_mse: 3602.4602\n",
            "Epoch 619/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.9621 - mse: 6.9621 - val_loss: 3707.4807 - val_mse: 3707.4807\n",
            "Epoch 620/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.2293 - mse: 6.2293 - val_loss: 3532.7449 - val_mse: 3532.7449\n",
            "Epoch 621/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 7.4117 - mse: 7.4117 - val_loss: 3492.7246 - val_mse: 3492.7246\n",
            "Epoch 622/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.8526 - mse: 6.8526 - val_loss: 3745.3848 - val_mse: 3745.3848\n",
            "Epoch 623/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.6166 - mse: 6.6166 - val_loss: 3644.2534 - val_mse: 3644.2534\n",
            "Epoch 624/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.8136 - mse: 6.8136 - val_loss: 3519.2869 - val_mse: 3519.2869\n",
            "Epoch 625/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.0897 - mse: 6.0897 - val_loss: 3689.1880 - val_mse: 3689.1880\n",
            "Epoch 626/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.3153 - mse: 6.3153 - val_loss: 3705.9651 - val_mse: 3705.9651\n",
            "Epoch 627/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.0979 - mse: 6.0979 - val_loss: 3551.1541 - val_mse: 3551.1541\n",
            "Epoch 628/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.0618 - mse: 6.0618 - val_loss: 3509.8218 - val_mse: 3509.8218\n",
            "Epoch 629/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.5489 - mse: 6.5489 - val_loss: 3673.9985 - val_mse: 3673.9985\n",
            "Epoch 630/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.4745 - mse: 6.4745 - val_loss: 3568.2783 - val_mse: 3568.2783\n",
            "Epoch 631/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.9725 - mse: 5.9725 - val_loss: 3642.6023 - val_mse: 3642.6023\n",
            "Epoch 632/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.0233 - mse: 6.0233 - val_loss: 3681.0916 - val_mse: 3681.0916\n",
            "Epoch 633/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.6758 - mse: 5.6758 - val_loss: 3552.4722 - val_mse: 3552.4722\n",
            "Epoch 634/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 6.2222 - mse: 6.2222 - val_loss: 3502.6384 - val_mse: 3502.6384\n",
            "Epoch 635/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.4833 - mse: 6.4833 - val_loss: 3720.4465 - val_mse: 3720.4465\n",
            "Epoch 636/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 6.2476 - mse: 6.2476 - val_loss: 3569.7485 - val_mse: 3569.7485\n",
            "Epoch 637/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.7694 - mse: 5.7694 - val_loss: 3605.6250 - val_mse: 3605.6250\n",
            "Epoch 638/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.6068 - mse: 5.6068 - val_loss: 3562.4097 - val_mse: 3562.4097\n",
            "Epoch 639/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.8086 - mse: 5.8086 - val_loss: 3616.2168 - val_mse: 3616.2168\n",
            "Epoch 640/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.4652 - mse: 5.4652 - val_loss: 3564.6245 - val_mse: 3564.6245\n",
            "Epoch 641/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.5381 - mse: 5.5381 - val_loss: 3560.5356 - val_mse: 3560.5356\n",
            "Epoch 642/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.6175 - mse: 5.6175 - val_loss: 3606.4028 - val_mse: 3606.4028\n",
            "Epoch 643/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.4008 - mse: 5.4008 - val_loss: 3644.5676 - val_mse: 3644.5676\n",
            "Epoch 644/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.4444 - mse: 5.4444 - val_loss: 3614.8457 - val_mse: 3614.8457\n",
            "Epoch 645/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.3377 - mse: 5.3377 - val_loss: 3502.6746 - val_mse: 3502.6746\n",
            "Epoch 646/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.7998 - mse: 5.7998 - val_loss: 3507.7627 - val_mse: 3507.7627\n",
            "Epoch 647/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.4294 - mse: 5.4294 - val_loss: 3719.3169 - val_mse: 3719.3169\n",
            "Epoch 648/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.5130 - mse: 5.5130 - val_loss: 3607.7651 - val_mse: 3607.7651\n",
            "Epoch 649/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.3658 - mse: 5.3658 - val_loss: 3525.3347 - val_mse: 3525.3347\n",
            "Epoch 650/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.5607 - mse: 5.5607 - val_loss: 3591.7456 - val_mse: 3591.7456\n",
            "Epoch 651/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.2474 - mse: 5.2474 - val_loss: 3704.3706 - val_mse: 3704.3706\n",
            "Epoch 652/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.5362 - mse: 5.5362 - val_loss: 3626.8560 - val_mse: 3626.8560\n",
            "Epoch 653/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.3608 - mse: 5.3608 - val_loss: 3651.3374 - val_mse: 3651.3374\n",
            "Epoch 654/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.6145 - mse: 5.6145 - val_loss: 3581.4778 - val_mse: 3581.4778\n",
            "Epoch 655/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.2626 - mse: 5.2626 - val_loss: 3719.5808 - val_mse: 3719.5808\n",
            "Epoch 656/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.2499 - mse: 5.2499 - val_loss: 3631.8765 - val_mse: 3631.8765\n",
            "Epoch 657/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.0219 - mse: 5.0219 - val_loss: 3612.6472 - val_mse: 3612.6472\n",
            "Epoch 658/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.1400 - mse: 5.1400 - val_loss: 3591.8035 - val_mse: 3591.8035\n",
            "Epoch 659/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 5.4040 - mse: 5.4040 - val_loss: 3668.2832 - val_mse: 3668.2832\n",
            "Epoch 660/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.8895 - mse: 4.8895 - val_loss: 3566.5491 - val_mse: 3566.5491\n",
            "Epoch 661/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.8982 - mse: 4.8982 - val_loss: 3598.7310 - val_mse: 3598.7310\n",
            "Epoch 662/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.8259 - mse: 4.8259 - val_loss: 3599.9238 - val_mse: 3599.9238\n",
            "Epoch 663/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.0656 - mse: 5.0656 - val_loss: 3595.1982 - val_mse: 3595.1982\n",
            "Epoch 664/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.7383 - mse: 4.7383 - val_loss: 3659.1646 - val_mse: 3659.1646\n",
            "Epoch 665/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.9367 - mse: 4.9367 - val_loss: 3570.8035 - val_mse: 3570.8035\n",
            "Epoch 666/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.9904 - mse: 4.9904 - val_loss: 3621.9136 - val_mse: 3621.9136\n",
            "Epoch 667/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 5.0543 - mse: 5.0543 - val_loss: 3521.3330 - val_mse: 3521.3330\n",
            "Epoch 668/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.7392 - mse: 4.7392 - val_loss: 3613.2471 - val_mse: 3613.2471\n",
            "Epoch 669/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.7549 - mse: 4.7549 - val_loss: 3658.0754 - val_mse: 3658.0754\n",
            "Epoch 670/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.7318 - mse: 4.7318 - val_loss: 3538.5669 - val_mse: 3538.5669\n",
            "Epoch 671/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.6252 - mse: 4.6252 - val_loss: 3600.2136 - val_mse: 3600.2136\n",
            "Epoch 672/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.5455 - mse: 4.5455 - val_loss: 3621.5229 - val_mse: 3621.5229\n",
            "Epoch 673/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.4665 - mse: 4.4665 - val_loss: 3601.8713 - val_mse: 3601.8713\n",
            "Epoch 674/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.3952 - mse: 4.3952 - val_loss: 3566.4863 - val_mse: 3566.4863\n",
            "Epoch 675/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.4790 - mse: 4.4790 - val_loss: 3551.1582 - val_mse: 3551.1582\n",
            "Epoch 676/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.6304 - mse: 4.6304 - val_loss: 3600.0696 - val_mse: 3600.0696\n",
            "Epoch 677/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.4585 - mse: 4.4585 - val_loss: 3529.7002 - val_mse: 3529.7002\n",
            "Epoch 678/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.4910 - mse: 4.4910 - val_loss: 3593.3770 - val_mse: 3593.3770\n",
            "Epoch 679/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.6676 - mse: 4.6676 - val_loss: 3693.2727 - val_mse: 3693.2727\n",
            "Epoch 680/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.3377 - mse: 4.3377 - val_loss: 3506.9646 - val_mse: 3506.9646\n",
            "Epoch 681/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.8060 - mse: 4.8060 - val_loss: 3511.0317 - val_mse: 3511.0317\n",
            "Epoch 682/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.3934 - mse: 4.3934 - val_loss: 3756.5293 - val_mse: 3756.5293\n",
            "Epoch 683/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.6861 - mse: 4.6861 - val_loss: 3581.4973 - val_mse: 3581.4973\n",
            "Epoch 684/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.4973 - mse: 4.4973 - val_loss: 3574.6831 - val_mse: 3574.6831\n",
            "Epoch 685/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.1738 - mse: 4.1738 - val_loss: 3605.6714 - val_mse: 3605.6714\n",
            "Epoch 686/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.3836 - mse: 4.3836 - val_loss: 3611.1365 - val_mse: 3611.1365\n",
            "Epoch 687/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.0739 - mse: 4.0739 - val_loss: 3527.7356 - val_mse: 3527.7356\n",
            "Epoch 688/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.3689 - mse: 4.3689 - val_loss: 3577.4915 - val_mse: 3577.4915\n",
            "Epoch 689/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.0636 - mse: 4.0636 - val_loss: 3619.4700 - val_mse: 3619.4700\n",
            "Epoch 690/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.2766 - mse: 4.2766 - val_loss: 3621.5198 - val_mse: 3621.5198\n",
            "Epoch 691/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 4.2689 - mse: 4.2689 - val_loss: 3493.5981 - val_mse: 3493.5981\n",
            "Epoch 692/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.1698 - mse: 4.1698 - val_loss: 3633.4856 - val_mse: 3633.4856\n",
            "Epoch 693/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.0710 - mse: 4.0710 - val_loss: 3609.7715 - val_mse: 3609.7715\n",
            "Epoch 694/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.9355 - mse: 3.9355 - val_loss: 3529.4036 - val_mse: 3529.4036\n",
            "Epoch 695/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.9516 - mse: 3.9516 - val_loss: 3577.9683 - val_mse: 3577.9683\n",
            "Epoch 696/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.0153 - mse: 4.0153 - val_loss: 3653.2957 - val_mse: 3653.2957\n",
            "Epoch 697/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.8577 - mse: 3.8577 - val_loss: 3544.8174 - val_mse: 3544.8174\n",
            "Epoch 698/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.9871 - mse: 3.9871 - val_loss: 3536.3855 - val_mse: 3536.3855\n",
            "Epoch 699/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 4.2040 - mse: 4.2040 - val_loss: 3645.5151 - val_mse: 3645.5151\n",
            "Epoch 700/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.9174 - mse: 3.9174 - val_loss: 3512.4673 - val_mse: 3512.4673\n",
            "Epoch 701/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.8976 - mse: 3.8976 - val_loss: 3597.7307 - val_mse: 3597.7307\n",
            "Epoch 702/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.7338 - mse: 3.7338 - val_loss: 3560.5435 - val_mse: 3560.5435\n",
            "Epoch 703/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.7211 - mse: 3.7211 - val_loss: 3530.2466 - val_mse: 3530.2466\n",
            "Epoch 704/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.8940 - mse: 3.8940 - val_loss: 3569.8225 - val_mse: 3569.8225\n",
            "Epoch 705/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.7378 - mse: 3.7378 - val_loss: 3582.7771 - val_mse: 3582.7771\n",
            "Epoch 706/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6809 - mse: 3.6809 - val_loss: 3571.9995 - val_mse: 3571.9995\n",
            "Epoch 707/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.6812 - mse: 3.6812 - val_loss: 3559.2124 - val_mse: 3559.2124\n",
            "Epoch 708/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6923 - mse: 3.6923 - val_loss: 3535.3396 - val_mse: 3535.3396\n",
            "Epoch 709/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6371 - mse: 3.6371 - val_loss: 3570.8230 - val_mse: 3570.8230\n",
            "Epoch 710/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6871 - mse: 3.6871 - val_loss: 3579.3081 - val_mse: 3579.3081\n",
            "Epoch 711/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.5937 - mse: 3.5937 - val_loss: 3647.5645 - val_mse: 3647.5645\n",
            "Epoch 712/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.5788 - mse: 3.5788 - val_loss: 3541.1860 - val_mse: 3541.1860\n",
            "Epoch 713/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6840 - mse: 3.6840 - val_loss: 3536.8948 - val_mse: 3536.8948\n",
            "Epoch 714/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.6055 - mse: 3.6055 - val_loss: 3650.4487 - val_mse: 3650.4487\n",
            "Epoch 715/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.6428 - mse: 3.6428 - val_loss: 3525.2500 - val_mse: 3525.2500\n",
            "Epoch 716/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.5234 - mse: 3.5234 - val_loss: 3517.4292 - val_mse: 3517.4292\n",
            "Epoch 717/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.4792 - mse: 3.4792 - val_loss: 3508.5198 - val_mse: 3508.5198\n",
            "Epoch 718/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.4867 - mse: 3.4867 - val_loss: 3570.2151 - val_mse: 3570.2151\n",
            "Epoch 719/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.4923 - mse: 3.4923 - val_loss: 3529.2417 - val_mse: 3529.2417\n",
            "Epoch 720/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.7537 - mse: 3.7537 - val_loss: 3591.3801 - val_mse: 3591.3801\n",
            "Epoch 721/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.4320 - mse: 3.4320 - val_loss: 3477.3372 - val_mse: 3477.3372\n",
            "Epoch 722/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.5068 - mse: 3.5068 - val_loss: 3622.3481 - val_mse: 3622.3481\n",
            "Epoch 723/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.5426 - mse: 3.5426 - val_loss: 3597.4773 - val_mse: 3597.4773\n",
            "Epoch 724/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2871 - mse: 3.2871 - val_loss: 3608.0886 - val_mse: 3608.0886\n",
            "Epoch 725/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2933 - mse: 3.2933 - val_loss: 3579.7427 - val_mse: 3579.7427\n",
            "Epoch 726/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.3791 - mse: 3.3791 - val_loss: 3579.9885 - val_mse: 3579.9885\n",
            "Epoch 727/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.4719 - mse: 3.4719 - val_loss: 3498.6924 - val_mse: 3498.6924\n",
            "Epoch 728/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.3006 - mse: 3.3006 - val_loss: 3652.1443 - val_mse: 3652.1443\n",
            "Epoch 729/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.4083 - mse: 3.4083 - val_loss: 3626.4370 - val_mse: 3626.4370\n",
            "Epoch 730/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.3670 - mse: 3.3670 - val_loss: 3492.3999 - val_mse: 3492.3999\n",
            "Epoch 731/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2198 - mse: 3.2198 - val_loss: 3616.9583 - val_mse: 3616.9583\n",
            "Epoch 732/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.2138 - mse: 3.2138 - val_loss: 3637.9255 - val_mse: 3637.9255\n",
            "Epoch 733/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.2375 - mse: 3.2375 - val_loss: 3543.1826 - val_mse: 3543.1826\n",
            "Epoch 734/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.1437 - mse: 3.1437 - val_loss: 3611.7136 - val_mse: 3611.7136\n",
            "Epoch 735/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.1204 - mse: 3.1204 - val_loss: 3596.8147 - val_mse: 3596.8147\n",
            "Epoch 736/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.1073 - mse: 3.1073 - val_loss: 3564.1604 - val_mse: 3564.1604\n",
            "Epoch 737/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.0705 - mse: 3.0705 - val_loss: 3622.9531 - val_mse: 3622.9531\n",
            "Epoch 738/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.1466 - mse: 3.1466 - val_loss: 3608.7715 - val_mse: 3608.7715\n",
            "Epoch 739/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.1588 - mse: 3.1588 - val_loss: 3519.8645 - val_mse: 3519.8645\n",
            "Epoch 740/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.0202 - mse: 3.0202 - val_loss: 3571.1316 - val_mse: 3571.1316\n",
            "Epoch 741/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.1530 - mse: 3.1530 - val_loss: 3554.6890 - val_mse: 3554.6890\n",
            "Epoch 742/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.0111 - mse: 3.0111 - val_loss: 3591.5405 - val_mse: 3591.5405\n",
            "Epoch 743/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.1044 - mse: 3.1044 - val_loss: 3522.8848 - val_mse: 3522.8848\n",
            "Epoch 744/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 3.2284 - mse: 3.2284 - val_loss: 3420.9148 - val_mse: 3420.9148\n",
            "Epoch 745/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9933 - mse: 2.9933 - val_loss: 3609.4824 - val_mse: 3609.4824\n",
            "Epoch 746/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.9117 - mse: 2.9117 - val_loss: 3626.8879 - val_mse: 3626.8879\n",
            "Epoch 747/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.9964 - mse: 2.9964 - val_loss: 3530.1160 - val_mse: 3530.1160\n",
            "Epoch 748/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.8626 - mse: 2.8626 - val_loss: 3474.6675 - val_mse: 3474.6675\n",
            "Epoch 749/1000\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8679 - mse: 2.8679 - val_loss: 3530.6550 - val_mse: 3530.6550\n",
            "Epoch 750/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.0611 - mse: 3.0611 - val_loss: 3567.5186 - val_mse: 3567.5186\n",
            "Epoch 751/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 3.2598 - mse: 3.2598 - val_loss: 3495.3088 - val_mse: 3495.3088\n",
            "Epoch 752/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.9722 - mse: 2.9722 - val_loss: 3572.8196 - val_mse: 3572.8196\n",
            "Epoch 753/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.9287 - mse: 2.9287 - val_loss: 3544.1675 - val_mse: 3544.1675\n",
            "Epoch 754/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.7490 - mse: 2.7490 - val_loss: 3497.1321 - val_mse: 3497.1321\n",
            "Epoch 755/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.9093 - mse: 2.9093 - val_loss: 3511.0708 - val_mse: 3511.0708\n",
            "Epoch 756/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6683 - mse: 2.6683 - val_loss: 3574.1038 - val_mse: 3574.1038\n",
            "Epoch 757/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.7064 - mse: 2.7064 - val_loss: 3487.8386 - val_mse: 3487.8386\n",
            "Epoch 758/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6410 - mse: 2.6410 - val_loss: 3421.0354 - val_mse: 3421.0354\n",
            "Epoch 759/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6618 - mse: 2.6618 - val_loss: 3476.0242 - val_mse: 3476.0242\n",
            "Epoch 760/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.7679 - mse: 2.7679 - val_loss: 3527.2363 - val_mse: 3527.2363\n",
            "Epoch 761/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6028 - mse: 2.6028 - val_loss: 3461.3259 - val_mse: 3461.3259\n",
            "Epoch 762/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6099 - mse: 2.6099 - val_loss: 3483.7542 - val_mse: 3483.7542\n",
            "Epoch 763/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.5545 - mse: 2.5545 - val_loss: 3498.7087 - val_mse: 3498.7087\n",
            "Epoch 764/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.6651 - mse: 2.6651 - val_loss: 3471.0547 - val_mse: 3471.0547\n",
            "Epoch 765/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5337 - mse: 2.5337 - val_loss: 3543.5554 - val_mse: 3543.5554\n",
            "Epoch 766/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.5724 - mse: 2.5724 - val_loss: 3478.1128 - val_mse: 3478.1128\n",
            "Epoch 767/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.5611 - mse: 2.5611 - val_loss: 3473.9312 - val_mse: 3473.9312\n",
            "Epoch 768/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.5347 - mse: 2.5347 - val_loss: 3521.7437 - val_mse: 3521.7437\n",
            "Epoch 769/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5779 - mse: 2.5779 - val_loss: 3472.2991 - val_mse: 3472.2991\n",
            "Epoch 770/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.4648 - mse: 2.4648 - val_loss: 3516.7925 - val_mse: 3516.7925\n",
            "Epoch 771/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5123 - mse: 2.5123 - val_loss: 3459.1833 - val_mse: 3459.1833\n",
            "Epoch 772/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4617 - mse: 2.4617 - val_loss: 3501.0889 - val_mse: 3501.0889\n",
            "Epoch 773/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3888 - mse: 2.3888 - val_loss: 3455.7024 - val_mse: 3455.7024\n",
            "Epoch 774/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.3441 - mse: 2.3441 - val_loss: 3513.2378 - val_mse: 3513.2378\n",
            "Epoch 775/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.4128 - mse: 2.4128 - val_loss: 3495.1470 - val_mse: 3495.1470\n",
            "Epoch 776/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3852 - mse: 2.3852 - val_loss: 3465.6011 - val_mse: 3465.6011\n",
            "Epoch 777/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5172 - mse: 2.5172 - val_loss: 3444.7954 - val_mse: 3444.7954\n",
            "Epoch 778/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3069 - mse: 2.3069 - val_loss: 3547.5286 - val_mse: 3547.5286\n",
            "Epoch 779/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.3169 - mse: 2.3169 - val_loss: 3496.6401 - val_mse: 3496.6401\n",
            "Epoch 780/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.3961 - mse: 2.3961 - val_loss: 3453.8174 - val_mse: 3453.8174\n",
            "Epoch 781/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.3019 - mse: 2.3019 - val_loss: 3556.0752 - val_mse: 3556.0752\n",
            "Epoch 782/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4650 - mse: 2.4650 - val_loss: 3470.3977 - val_mse: 3470.3977\n",
            "Epoch 783/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.6517 - mse: 2.6517 - val_loss: 3406.4211 - val_mse: 3406.4211\n",
            "Epoch 784/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.4259 - mse: 2.4259 - val_loss: 3633.3979 - val_mse: 3633.3979\n",
            "Epoch 785/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5362 - mse: 2.5362 - val_loss: 3572.8181 - val_mse: 3572.8181\n",
            "Epoch 786/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.6918 - mse: 2.6918 - val_loss: 3429.3281 - val_mse: 3429.3281\n",
            "Epoch 787/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.2068 - mse: 2.2068 - val_loss: 3616.2854 - val_mse: 3616.2854\n",
            "Epoch 788/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.5153 - mse: 2.5153 - val_loss: 3547.5640 - val_mse: 3547.5640\n",
            "Epoch 789/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.2844 - mse: 2.2844 - val_loss: 3306.5107 - val_mse: 3306.5107\n",
            "Epoch 790/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.3112 - mse: 2.3112 - val_loss: 3464.5425 - val_mse: 3464.5425\n",
            "Epoch 791/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.2087 - mse: 2.2087 - val_loss: 3442.4915 - val_mse: 3442.4915\n",
            "Epoch 792/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.1943 - mse: 2.1943 - val_loss: 3398.3989 - val_mse: 3398.3989\n",
            "Epoch 793/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.1728 - mse: 2.1728 - val_loss: 3406.6414 - val_mse: 3406.6414\n",
            "Epoch 794/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.2696 - mse: 2.2696 - val_loss: 3517.7649 - val_mse: 3517.7649\n",
            "Epoch 795/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.2007 - mse: 2.2007 - val_loss: 3530.0161 - val_mse: 3530.0161\n",
            "Epoch 796/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.1017 - mse: 2.1017 - val_loss: 3471.2466 - val_mse: 3471.2466\n",
            "Epoch 797/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.1065 - mse: 2.1065 - val_loss: 3444.4595 - val_mse: 3444.4595\n",
            "Epoch 798/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.0973 - mse: 2.0973 - val_loss: 3527.6333 - val_mse: 3527.6333\n",
            "Epoch 799/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.1154 - mse: 2.1154 - val_loss: 3485.0476 - val_mse: 3485.0476\n",
            "Epoch 800/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.1181 - mse: 2.1181 - val_loss: 3441.5859 - val_mse: 3441.5859\n",
            "Epoch 801/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.1205 - mse: 2.1205 - val_loss: 3418.6926 - val_mse: 3418.6926\n",
            "Epoch 802/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0046 - mse: 2.0046 - val_loss: 3520.4331 - val_mse: 3520.4331\n",
            "Epoch 803/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.1350 - mse: 2.1350 - val_loss: 3447.6648 - val_mse: 3447.6648\n",
            "Epoch 804/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0826 - mse: 2.0826 - val_loss: 3425.0115 - val_mse: 3425.0115\n",
            "Epoch 805/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.0695 - mse: 2.0695 - val_loss: 3467.2332 - val_mse: 3467.2332\n",
            "Epoch 806/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.0442 - mse: 2.0442 - val_loss: 3487.1655 - val_mse: 3487.1655\n",
            "Epoch 807/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.0065 - mse: 2.0065 - val_loss: 3468.6582 - val_mse: 3468.6582\n",
            "Epoch 808/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9727 - mse: 1.9727 - val_loss: 3473.9409 - val_mse: 3473.9409\n",
            "Epoch 809/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.0146 - mse: 2.0146 - val_loss: 3411.9817 - val_mse: 3411.9817\n",
            "Epoch 810/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9831 - mse: 1.9831 - val_loss: 3468.4839 - val_mse: 3468.4839\n",
            "Epoch 811/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 2.0473 - mse: 2.0473 - val_loss: 3462.5483 - val_mse: 3462.5483\n",
            "Epoch 812/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9597 - mse: 1.9597 - val_loss: 3395.3999 - val_mse: 3395.3999\n",
            "Epoch 813/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9239 - mse: 1.9239 - val_loss: 3504.4817 - val_mse: 3504.4817\n",
            "Epoch 814/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9743 - mse: 1.9743 - val_loss: 3495.7429 - val_mse: 3495.7429\n",
            "Epoch 815/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8658 - mse: 1.8658 - val_loss: 3407.2668 - val_mse: 3407.2668\n",
            "Epoch 816/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9697 - mse: 1.9697 - val_loss: 3511.0688 - val_mse: 3511.0688\n",
            "Epoch 817/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9076 - mse: 1.9076 - val_loss: 3457.7974 - val_mse: 3457.7974\n",
            "Epoch 818/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9242 - mse: 1.9242 - val_loss: 3500.2351 - val_mse: 3500.2351\n",
            "Epoch 819/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8706 - mse: 1.8706 - val_loss: 3467.6953 - val_mse: 3467.6953\n",
            "Epoch 820/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8464 - mse: 1.8464 - val_loss: 3476.0142 - val_mse: 3476.0142\n",
            "Epoch 821/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8763 - mse: 1.8763 - val_loss: 3469.4553 - val_mse: 3469.4553\n",
            "Epoch 822/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9108 - mse: 1.9108 - val_loss: 3450.5847 - val_mse: 3450.5847\n",
            "Epoch 823/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8429 - mse: 1.8429 - val_loss: 3462.7998 - val_mse: 3462.7998\n",
            "Epoch 824/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8940 - mse: 1.8940 - val_loss: 3436.0327 - val_mse: 3436.0327\n",
            "Epoch 825/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8254 - mse: 1.8254 - val_loss: 3356.5142 - val_mse: 3356.5142\n",
            "Epoch 826/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7971 - mse: 1.7971 - val_loss: 3463.4270 - val_mse: 3463.4270\n",
            "Epoch 827/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7891 - mse: 1.7891 - val_loss: 3433.9333 - val_mse: 3433.9333\n",
            "Epoch 828/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8065 - mse: 1.8065 - val_loss: 3387.0134 - val_mse: 3387.0134\n",
            "Epoch 829/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7486 - mse: 1.7486 - val_loss: 3490.8535 - val_mse: 3490.8535\n",
            "Epoch 830/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8088 - mse: 1.8088 - val_loss: 3437.3125 - val_mse: 3437.3125\n",
            "Epoch 831/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7642 - mse: 1.7642 - val_loss: 3423.9590 - val_mse: 3423.9590\n",
            "Epoch 832/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7521 - mse: 1.7521 - val_loss: 3435.5872 - val_mse: 3435.5872\n",
            "Epoch 833/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7281 - mse: 1.7281 - val_loss: 3392.1050 - val_mse: 3392.1050\n",
            "Epoch 834/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7643 - mse: 1.7643 - val_loss: 3530.1763 - val_mse: 3530.1763\n",
            "Epoch 835/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9317 - mse: 1.9317 - val_loss: 3441.4565 - val_mse: 3441.4565\n",
            "Epoch 836/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8008 - mse: 1.8008 - val_loss: 3335.3005 - val_mse: 3335.3005\n",
            "Epoch 837/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8278 - mse: 1.8278 - val_loss: 3454.9888 - val_mse: 3454.9888\n",
            "Epoch 838/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7553 - mse: 1.7553 - val_loss: 3403.9683 - val_mse: 3403.9683\n",
            "Epoch 839/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 2.0674 - mse: 2.0674 - val_loss: 3403.0811 - val_mse: 3403.0811\n",
            "Epoch 840/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6834 - mse: 1.6834 - val_loss: 3554.3730 - val_mse: 3554.3730\n",
            "Epoch 841/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.8422 - mse: 1.8422 - val_loss: 3364.2471 - val_mse: 3364.2471\n",
            "Epoch 842/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.9467 - mse: 1.9467 - val_loss: 3471.0957 - val_mse: 3471.0957\n",
            "Epoch 843/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9194 - mse: 1.9194 - val_loss: 3540.1199 - val_mse: 3540.1199\n",
            "Epoch 844/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.9511 - mse: 1.9511 - val_loss: 3380.9395 - val_mse: 3380.9395\n",
            "Epoch 845/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5906 - mse: 1.5906 - val_loss: 3554.4353 - val_mse: 3554.4353\n",
            "Epoch 846/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7606 - mse: 1.7606 - val_loss: 3432.5718 - val_mse: 3432.5718\n",
            "Epoch 847/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6958 - mse: 1.6958 - val_loss: 3413.2109 - val_mse: 3413.2109\n",
            "Epoch 848/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7570 - mse: 1.7570 - val_loss: 3441.9822 - val_mse: 3441.9822\n",
            "Epoch 849/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6632 - mse: 1.6632 - val_loss: 3348.7102 - val_mse: 3348.7102\n",
            "Epoch 850/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6693 - mse: 1.6693 - val_loss: 3504.9475 - val_mse: 3504.9475\n",
            "Epoch 851/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6662 - mse: 1.6662 - val_loss: 3406.6980 - val_mse: 3406.6980\n",
            "Epoch 852/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5936 - mse: 1.5936 - val_loss: 3352.0391 - val_mse: 3352.0391\n",
            "Epoch 853/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5949 - mse: 1.5949 - val_loss: 3421.1406 - val_mse: 3421.1406\n",
            "Epoch 854/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7231 - mse: 1.7231 - val_loss: 3430.1880 - val_mse: 3430.1880\n",
            "Epoch 855/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8532 - mse: 1.8532 - val_loss: 3366.8601 - val_mse: 3366.8601\n",
            "Epoch 856/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7520 - mse: 1.7520 - val_loss: 3550.1738 - val_mse: 3550.1738\n",
            "Epoch 857/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6640 - mse: 1.6640 - val_loss: 3396.8457 - val_mse: 3396.8457\n",
            "Epoch 858/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.7072 - mse: 1.7072 - val_loss: 3444.6582 - val_mse: 3444.6582\n",
            "Epoch 859/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.7459 - mse: 1.7459 - val_loss: 3456.6804 - val_mse: 3456.6804\n",
            "Epoch 860/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.8044 - mse: 1.8044 - val_loss: 3349.5410 - val_mse: 3349.5410\n",
            "Epoch 861/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6418 - mse: 1.6418 - val_loss: 3503.8396 - val_mse: 3503.8396\n",
            "Epoch 862/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6403 - mse: 1.6403 - val_loss: 3413.5520 - val_mse: 3413.5520\n",
            "Epoch 863/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5988 - mse: 1.5988 - val_loss: 3338.3474 - val_mse: 3338.3474\n",
            "Epoch 864/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4982 - mse: 1.4982 - val_loss: 3406.4988 - val_mse: 3406.4988\n",
            "Epoch 865/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.5618 - mse: 1.5618 - val_loss: 3349.7307 - val_mse: 3349.7307\n",
            "Epoch 866/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5931 - mse: 1.5931 - val_loss: 3337.1880 - val_mse: 3337.1880\n",
            "Epoch 867/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6872 - mse: 1.6872 - val_loss: 3451.0525 - val_mse: 3451.0525\n",
            "Epoch 868/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.6119 - mse: 1.6119 - val_loss: 3328.2026 - val_mse: 3328.2026\n",
            "Epoch 869/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5329 - mse: 1.5329 - val_loss: 3460.0198 - val_mse: 3460.0198\n",
            "Epoch 870/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4953 - mse: 1.4953 - val_loss: 3403.2991 - val_mse: 3403.2991\n",
            "Epoch 871/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4722 - mse: 1.4722 - val_loss: 3396.4189 - val_mse: 3396.4189\n",
            "Epoch 872/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4644 - mse: 1.4644 - val_loss: 3434.6042 - val_mse: 3434.6042\n",
            "Epoch 873/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5107 - mse: 1.5107 - val_loss: 3407.6707 - val_mse: 3407.6707\n",
            "Epoch 874/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5076 - mse: 1.5076 - val_loss: 3419.2434 - val_mse: 3419.2434\n",
            "Epoch 875/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5620 - mse: 1.5620 - val_loss: 3376.9233 - val_mse: 3376.9233\n",
            "Epoch 876/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4767 - mse: 1.4767 - val_loss: 3336.4309 - val_mse: 3336.4309\n",
            "Epoch 877/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4705 - mse: 1.4705 - val_loss: 3435.4126 - val_mse: 3435.4126\n",
            "Epoch 878/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4749 - mse: 1.4749 - val_loss: 3371.8667 - val_mse: 3371.8667\n",
            "Epoch 879/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4168 - mse: 1.4168 - val_loss: 3366.3713 - val_mse: 3366.3713\n",
            "Epoch 880/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4067 - mse: 1.4067 - val_loss: 3334.5603 - val_mse: 3334.5603\n",
            "Epoch 881/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3958 - mse: 1.3958 - val_loss: 3356.0059 - val_mse: 3356.0059\n",
            "Epoch 882/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4721 - mse: 1.4721 - val_loss: 3322.0823 - val_mse: 3322.0823\n",
            "Epoch 883/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4931 - mse: 1.4931 - val_loss: 3329.6890 - val_mse: 3329.6890\n",
            "Epoch 884/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3886 - mse: 1.3886 - val_loss: 3476.6677 - val_mse: 3476.6677\n",
            "Epoch 885/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4300 - mse: 1.4300 - val_loss: 3368.9019 - val_mse: 3368.9019\n",
            "Epoch 886/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4793 - mse: 1.4793 - val_loss: 3406.0566 - val_mse: 3406.0566\n",
            "Epoch 887/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4557 - mse: 1.4557 - val_loss: 3453.6667 - val_mse: 3453.6667\n",
            "Epoch 888/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4200 - mse: 1.4200 - val_loss: 3382.0347 - val_mse: 3382.0347\n",
            "Epoch 889/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4022 - mse: 1.4022 - val_loss: 3396.0247 - val_mse: 3396.0247\n",
            "Epoch 890/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4064 - mse: 1.4064 - val_loss: 3391.5662 - val_mse: 3391.5662\n",
            "Epoch 891/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4716 - mse: 1.4716 - val_loss: 3392.6042 - val_mse: 3392.6042\n",
            "Epoch 892/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3737 - mse: 1.3737 - val_loss: 3309.7827 - val_mse: 3309.7827\n",
            "Epoch 893/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4723 - mse: 1.4723 - val_loss: 3436.8088 - val_mse: 3436.8088\n",
            "Epoch 894/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4034 - mse: 1.4034 - val_loss: 3407.1377 - val_mse: 3407.1377\n",
            "Epoch 895/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3855 - mse: 1.3855 - val_loss: 3276.5591 - val_mse: 3276.5591\n",
            "Epoch 896/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3693 - mse: 1.3693 - val_loss: 3388.3325 - val_mse: 3388.3325\n",
            "Epoch 897/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5490 - mse: 1.5490 - val_loss: 3423.5933 - val_mse: 3423.5933\n",
            "Epoch 898/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4830 - mse: 1.4830 - val_loss: 3167.4119 - val_mse: 3167.4119\n",
            "Epoch 899/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4531 - mse: 1.4531 - val_loss: 3429.7363 - val_mse: 3429.7363\n",
            "Epoch 900/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.6482 - mse: 1.6482 - val_loss: 3433.5645 - val_mse: 3433.5645\n",
            "Epoch 901/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5942 - mse: 1.5942 - val_loss: 3391.9517 - val_mse: 3391.9517\n",
            "Epoch 902/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3501 - mse: 1.3501 - val_loss: 3485.5933 - val_mse: 3485.5933\n",
            "Epoch 903/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3888 - mse: 1.3888 - val_loss: 3389.9226 - val_mse: 3389.9226\n",
            "Epoch 904/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3534 - mse: 1.3534 - val_loss: 3352.4753 - val_mse: 3352.4753\n",
            "Epoch 905/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2966 - mse: 1.2966 - val_loss: 3474.1362 - val_mse: 3474.1362\n",
            "Epoch 906/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4220 - mse: 1.4220 - val_loss: 3377.2104 - val_mse: 3377.2104\n",
            "Epoch 907/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2744 - mse: 1.2744 - val_loss: 3393.7690 - val_mse: 3393.7690\n",
            "Epoch 908/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3453 - mse: 1.3453 - val_loss: 3312.3989 - val_mse: 3312.3989\n",
            "Epoch 909/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.4169 - mse: 1.4169 - val_loss: 3405.5234 - val_mse: 3405.5234\n",
            "Epoch 910/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4685 - mse: 1.4685 - val_loss: 3404.0386 - val_mse: 3404.0386\n",
            "Epoch 911/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3062 - mse: 1.3062 - val_loss: 3269.3840 - val_mse: 3269.3840\n",
            "Epoch 912/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3667 - mse: 1.3667 - val_loss: 3431.5320 - val_mse: 3431.5320\n",
            "Epoch 913/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3968 - mse: 1.3968 - val_loss: 3381.5925 - val_mse: 3381.5925\n",
            "Epoch 914/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3190 - mse: 1.3190 - val_loss: 3340.7771 - val_mse: 3340.7771\n",
            "Epoch 915/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2568 - mse: 1.2568 - val_loss: 3298.8174 - val_mse: 3298.8174\n",
            "Epoch 916/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2219 - mse: 1.2219 - val_loss: 3327.3745 - val_mse: 3327.3745\n",
            "Epoch 917/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2285 - mse: 1.2285 - val_loss: 3405.0769 - val_mse: 3405.0769\n",
            "Epoch 918/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2825 - mse: 1.2825 - val_loss: 3351.8308 - val_mse: 3351.8308\n",
            "Epoch 919/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3217 - mse: 1.3217 - val_loss: 3330.4910 - val_mse: 3330.4910\n",
            "Epoch 920/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2458 - mse: 1.2458 - val_loss: 3389.3188 - val_mse: 3389.3188\n",
            "Epoch 921/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1955 - mse: 1.1955 - val_loss: 3317.8538 - val_mse: 3317.8538\n",
            "Epoch 922/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2308 - mse: 1.2308 - val_loss: 3375.3276 - val_mse: 3375.3276\n",
            "Epoch 923/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2121 - mse: 1.2121 - val_loss: 3336.2869 - val_mse: 3336.2869\n",
            "Epoch 924/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1934 - mse: 1.1934 - val_loss: 3347.7053 - val_mse: 3347.7053\n",
            "Epoch 925/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2474 - mse: 1.2474 - val_loss: 3358.6685 - val_mse: 3358.6685\n",
            "Epoch 926/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3156 - mse: 1.3156 - val_loss: 3313.6499 - val_mse: 3313.6499\n",
            "Epoch 927/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3336 - mse: 1.3336 - val_loss: 3276.2808 - val_mse: 3276.2808\n",
            "Epoch 928/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3401 - mse: 1.3401 - val_loss: 3322.7729 - val_mse: 3322.7729\n",
            "Epoch 929/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3223 - mse: 1.3223 - val_loss: 3327.6619 - val_mse: 3327.6619\n",
            "Epoch 930/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1570 - mse: 1.1570 - val_loss: 3304.6775 - val_mse: 3304.6775\n",
            "Epoch 931/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1609 - mse: 1.1609 - val_loss: 3294.8474 - val_mse: 3294.8474\n",
            "Epoch 932/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1994 - mse: 1.1994 - val_loss: 3332.6106 - val_mse: 3332.6106\n",
            "Epoch 933/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2420 - mse: 1.2420 - val_loss: 3266.0090 - val_mse: 3266.0090\n",
            "Epoch 934/1000\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2193 - mse: 1.2193 - val_loss: 3282.3423 - val_mse: 3282.3423\n",
            "Epoch 935/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2284 - mse: 1.2284 - val_loss: 3397.8677 - val_mse: 3397.8677\n",
            "Epoch 936/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2058 - mse: 1.2058 - val_loss: 3340.9568 - val_mse: 3340.9568\n",
            "Epoch 937/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1273 - mse: 1.1273 - val_loss: 3415.5078 - val_mse: 3415.5078\n",
            "Epoch 938/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1642 - mse: 1.1642 - val_loss: 3382.6284 - val_mse: 3382.6284\n",
            "Epoch 939/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1710 - mse: 1.1710 - val_loss: 3387.3345 - val_mse: 3387.3345\n",
            "Epoch 940/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2344 - mse: 1.2344 - val_loss: 3325.1414 - val_mse: 3325.1414\n",
            "Epoch 941/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3254 - mse: 1.3254 - val_loss: 3341.6348 - val_mse: 3341.6348\n",
            "Epoch 942/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2795 - mse: 1.2795 - val_loss: 3430.6064 - val_mse: 3430.6064\n",
            "Epoch 943/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1427 - mse: 1.1427 - val_loss: 3256.8813 - val_mse: 3256.8813\n",
            "Epoch 944/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3527 - mse: 1.3527 - val_loss: 3427.5796 - val_mse: 3427.5796\n",
            "Epoch 945/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3692 - mse: 1.3692 - val_loss: 3250.2004 - val_mse: 3250.2004\n",
            "Epoch 946/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4220 - mse: 1.4220 - val_loss: 3338.7715 - val_mse: 3338.7715\n",
            "Epoch 947/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.4314 - mse: 1.4314 - val_loss: 3486.3394 - val_mse: 3486.3394\n",
            "Epoch 948/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.3292 - mse: 1.3292 - val_loss: 3327.0513 - val_mse: 3327.0513\n",
            "Epoch 949/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.2850 - mse: 1.2850 - val_loss: 3419.8677 - val_mse: 3419.8677\n",
            "Epoch 950/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1784 - mse: 1.1784 - val_loss: 3355.8501 - val_mse: 3355.8501\n",
            "Epoch 951/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1610 - mse: 1.1610 - val_loss: 3406.1838 - val_mse: 3406.1838\n",
            "Epoch 952/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1820 - mse: 1.1820 - val_loss: 3311.7991 - val_mse: 3311.7991\n",
            "Epoch 953/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2132 - mse: 1.2132 - val_loss: 3402.6838 - val_mse: 3402.6838\n",
            "Epoch 954/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1650 - mse: 1.1650 - val_loss: 3411.2300 - val_mse: 3411.2300\n",
            "Epoch 955/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1640 - mse: 1.1640 - val_loss: 3363.5625 - val_mse: 3363.5625\n",
            "Epoch 956/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0846 - mse: 1.0846 - val_loss: 3362.6677 - val_mse: 3362.6677\n",
            "Epoch 957/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0476 - mse: 1.0476 - val_loss: 3339.4675 - val_mse: 3339.4675\n",
            "Epoch 958/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0555 - mse: 1.0555 - val_loss: 3371.8418 - val_mse: 3371.8418\n",
            "Epoch 959/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0606 - mse: 1.0606 - val_loss: 3321.1128 - val_mse: 3321.1128\n",
            "Epoch 960/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0579 - mse: 1.0579 - val_loss: 3317.0249 - val_mse: 3317.0249\n",
            "Epoch 961/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0621 - mse: 1.0621 - val_loss: 3408.7036 - val_mse: 3408.7036\n",
            "Epoch 962/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0602 - mse: 1.0602 - val_loss: 3321.4788 - val_mse: 3321.4788\n",
            "Epoch 963/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1108 - mse: 1.1108 - val_loss: 3386.3940 - val_mse: 3386.3940\n",
            "Epoch 964/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1762 - mse: 1.1762 - val_loss: 3316.7095 - val_mse: 3316.7095\n",
            "Epoch 965/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1002 - mse: 1.1002 - val_loss: 3334.4111 - val_mse: 3334.4111\n",
            "Epoch 966/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1669 - mse: 1.1669 - val_loss: 3325.5134 - val_mse: 3325.5134\n",
            "Epoch 967/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0512 - mse: 1.0512 - val_loss: 3280.4412 - val_mse: 3280.4412\n",
            "Epoch 968/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0695 - mse: 1.0695 - val_loss: 3403.8828 - val_mse: 3403.8828\n",
            "Epoch 969/1000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 1.0561 - mse: 1.0561 - val_loss: 3341.5676 - val_mse: 3341.5676\n",
            "Epoch 970/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0375 - mse: 1.0375 - val_loss: 3334.5793 - val_mse: 3334.5793\n",
            "Epoch 971/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0588 - mse: 1.0588 - val_loss: 3332.2664 - val_mse: 3332.2664\n",
            "Epoch 972/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 3309.9473 - val_mse: 3309.9473\n",
            "Epoch 973/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0151 - mse: 1.0151 - val_loss: 3339.8076 - val_mse: 3339.8076\n",
            "Epoch 974/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1137 - mse: 1.1137 - val_loss: 3362.0952 - val_mse: 3362.0952\n",
            "Epoch 975/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1178 - mse: 1.1178 - val_loss: 3300.3152 - val_mse: 3300.3152\n",
            "Epoch 976/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1468 - mse: 1.1468 - val_loss: 3352.1099 - val_mse: 3352.1099\n",
            "Epoch 977/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.2106 - mse: 1.2106 - val_loss: 3306.3438 - val_mse: 3306.3438\n",
            "Epoch 978/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0684 - mse: 1.0684 - val_loss: 3290.0369 - val_mse: 3290.0369\n",
            "Epoch 979/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0532 - mse: 1.0532 - val_loss: 3406.8699 - val_mse: 3406.8699\n",
            "Epoch 980/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.1004 - mse: 1.1004 - val_loss: 3303.6057 - val_mse: 3303.6057\n",
            "Epoch 981/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.1381 - mse: 1.1381 - val_loss: 3316.4714 - val_mse: 3316.4714\n",
            "Epoch 982/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0746 - mse: 1.0746 - val_loss: 3313.9817 - val_mse: 3313.9817\n",
            "Epoch 983/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9550 - mse: 0.9550 - val_loss: 3398.3118 - val_mse: 3398.3118\n",
            "Epoch 984/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0519 - mse: 1.0519 - val_loss: 3332.3020 - val_mse: 3332.3020\n",
            "Epoch 985/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0316 - mse: 1.0316 - val_loss: 3276.2104 - val_mse: 3276.2104\n",
            "Epoch 986/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0020 - mse: 1.0020 - val_loss: 3365.7622 - val_mse: 3365.7622\n",
            "Epoch 987/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 3304.5347 - val_mse: 3304.5347\n",
            "Epoch 988/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.0475 - mse: 1.0475 - val_loss: 3301.7566 - val_mse: 3301.7566\n",
            "Epoch 989/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.0427 - mse: 1.0427 - val_loss: 3405.1880 - val_mse: 3405.1880\n",
            "Epoch 990/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9658 - mse: 0.9658 - val_loss: 3293.8210 - val_mse: 3293.8210\n",
            "Epoch 991/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9491 - mse: 0.9491 - val_loss: 3344.9404 - val_mse: 3344.9404\n",
            "Epoch 992/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9548 - mse: 0.9548 - val_loss: 3309.5674 - val_mse: 3309.5674\n",
            "Epoch 993/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9535 - mse: 0.9535 - val_loss: 3326.8538 - val_mse: 3326.8538\n",
            "Epoch 994/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9294 - mse: 0.9294 - val_loss: 3330.1335 - val_mse: 3330.1335\n",
            "Epoch 995/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9431 - mse: 0.9431 - val_loss: 3308.0942 - val_mse: 3308.0942\n",
            "Epoch 996/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9418 - mse: 0.9418 - val_loss: 3326.3091 - val_mse: 3326.3091\n",
            "Epoch 997/1000\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9199 - mse: 0.9199 - val_loss: 3294.2122 - val_mse: 3294.2122\n",
            "Epoch 998/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9438 - mse: 0.9438 - val_loss: 3317.5171 - val_mse: 3317.5171\n",
            "Epoch 999/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9567 - mse: 0.9567 - val_loss: 3302.9495 - val_mse: 3302.9495\n",
            "Epoch 1000/1000\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.9503 - mse: 0.9503 - val_loss: 3335.2358 - val_mse: 3335.2358\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}